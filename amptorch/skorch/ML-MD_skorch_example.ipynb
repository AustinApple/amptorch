{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ase\n",
    "import time\n",
    "import sys\n",
    "import torch\n",
    "from torch.nn import MSELoss\n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.dataset import CVSplit\n",
    "from skorch.callbacks import Checkpoint, EpochScoring\n",
    "from amptorch.gaussian import Gaussian\n",
    "from amptorch.skorch.model_skorch import FullNN, CustomLoss\n",
    "from amptorch.skorch.skorch_data import AtomsDataset, factorize_data, collate_amp, TestDataset\n",
    "from amptorch.skorch.skorch_utils import md_run, calculate_energies, calculate_forces, time_plots, kde_plots\n",
    "from amptorch.skorch import AMP\n",
    "from amptorch.lj_model import lj_optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import init\n",
    "from skorch.utils import to_numpy\n",
    "import numpy as np\n",
    "from ase import Atoms, units\n",
    "from ase.calculators.emt import EMT\n",
    "from ase.md import Langevin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions needed to allow skorch to report energy and force rmse\n",
    "def target_extractor(y):\n",
    "    return (\n",
    "        (to_numpy(y[0]), to_numpy(y[1]))\n",
    "        if len(y) == 2\n",
    "        else (to_numpy(y[0]), to_numpy(y[1]), to_numpy(y[2]))\n",
    "    )\n",
    "\n",
    "def energy_score(net, X, y):\n",
    "    mse_loss = MSELoss(reduction=\"sum\")\n",
    "    energy_pred = net.infer()[0]\n",
    "    device = energy_pred.device\n",
    "    energy_target = torch.tensor(y[0]).to(device)\n",
    "    num_atoms = torch.tensor(y[1]).to(device)\n",
    "    dataset_size = len(energy_pred)\n",
    "    sd_scaling = scalings[0]\n",
    "    mean_scaling = scalings[1]\n",
    "    raw_preds = (energy_pred * sd_scaling) + mean_scaling\n",
    "    raw_preds_per_atom = torch.div(raw_preds, num_atoms)\n",
    "    raw_targets = (energy_target * sd_scaling) + mean_scaling\n",
    "    target_per_atom = torch.div(raw_targets, num_atoms)\n",
    "    energy_loss = mse_loss(raw_preds_per_atom, target_per_atom)\n",
    "    energy_loss /= dataset_size\n",
    "    energy_rmse = torch.sqrt(energy_loss)\n",
    "    return energy_rmse\n",
    "\n",
    "def forces_score(net, X, y):\n",
    "    mse_loss = MSELoss(reduction=\"sum\")\n",
    "    sd_scaling = scalings[0]\n",
    "    force_pred = net.infer()[1] * sd_scaling\n",
    "    device = force_pred.device\n",
    "    num_atoms = torch.tensor(y[1]).to(device)\n",
    "    force_target = torch.tensor(y[-1], device=device)\n",
    "    dataset_size = len(num_atoms)\n",
    "    raw_force_target = force_target * sd_scaling\n",
    "    num_atoms_force = torch.cat([idx.repeat(int(idx)) for idx in num_atoms])\n",
    "    num_atoms_force = torch.sqrt(num_atoms_force).reshape(len(num_atoms_force), 1)\n",
    "    force_pred_per_atom = torch.div(force_pred, num_atoms_force)\n",
    "    force_targets_per_atom = torch.div(raw_force_target, num_atoms_force)\n",
    "    force_mse = mse_loss(force_pred_per_atom, force_targets_per_atom)\n",
    "    force_mse /= 3 * dataset_size\n",
    "    force_rmse = torch.sqrt(force_mse)\n",
    "    return force_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define symmetry functions to be used\n",
    "Gs = {}\n",
    "Gs[\"G2_etas\"] = np.logspace(np.log10(0.05), np.log10(5.0), num=4)\n",
    "Gs[\"G2_rs_s\"] = [0] * 4\n",
    "Gs[\"G4_etas\"] = [0.005]\n",
    "Gs[\"G4_zetas\"] = [1.0, 4.0]\n",
    "Gs[\"G4_gammas\"] = [+1.0, -1]\n",
    "Gs[\"cutoff\"] = 6.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LJ Optimization\n",
    "def lj_optimization(images, Gs, label):\n",
    "    cutoff = Gs[\"cutoff\"]\n",
    "    p0 = [\n",
    "        1.33905162,\n",
    "        0.12290683,\n",
    "        6.41914719,\n",
    "        0.64021468,\n",
    "        0.08010004,\n",
    "        8.26082762,\n",
    "        2.29284676,\n",
    "        0.29639983,\n",
    "        0.08071821,\n",
    "    ]\n",
    "    params_dict = {\"C\": [], \"O\": [], \"Cu\": []}\n",
    "    lj_model = lj_optim(label, images, p0, params_dict, cutoff)\n",
    "    fitted_params = lj_model.fit()\n",
    "    lj_energies, lj_forces, num_atoms = lj_model.lj_pred(\n",
    "        images, fitted_params, params_dict\n",
    "    )\n",
    "    lj_data = [\n",
    "        lj_energies,\n",
    "        lj_forces,\n",
    "        num_atoms,\n",
    "        fitted_params,\n",
    "        params_dict,\n",
    "        lj_model,\n",
    "    ]\n",
    "    return lj_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Training data\n",
    "label = \"skorch_example\"\n",
    "images = ase.io.read(\"../../datasets/COCu/COCu_pbc_300K.traj\", \":100\")\n",
    "lj_data = lj_optimization(images, Gs, label)\n",
    "forcetraining = True\n",
    "training_data = AtomsDataset(images, Gaussian, Gs, forcetraining=forcetraining,\n",
    "        label=label, cores=1, lj_data=lj_data)\n",
    "scalings = training_data.scalings\n",
    "unique_atoms = training_data.elements\n",
    "fp_length = training_data.fp_length\n",
    "device = \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetRegressor(\n",
    "    module=FullNN(unique_atoms, [fp_length, 30, 30], device, forcetraining=forcetraining),\n",
    "    criterion=CustomLoss,\n",
    "    criterion__force_coefficient=0.3,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=1e-2,\n",
    "    batch_size=100,\n",
    "    max_epochs=500,\n",
    "    iterator_train__collate_fn=collate_amp,\n",
    "    iterator_valid__collate_fn=collate_amp,\n",
    "    device=device,\n",
    "    train_split=CVSplit(0.1),\n",
    "    callbacks=[\n",
    "        EpochScoring(\n",
    "            forces_score,\n",
    "            on_train=True,\n",
    "            use_caching=True,\n",
    "            target_extractor=target_extractor,\n",
    "        ),\n",
    "        EpochScoring(\n",
    "            energy_score,\n",
    "            on_train=True,\n",
    "            use_caching=True,\n",
    "            target_extractor=target_extractor,\n",
    "        ),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define calculator and train\n",
    "calc = AMP(training_data, net, label=label)\n",
    "calc.train(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MD Simulation\n",
    "md_run(calc=calc, starting_image=images[0].copy(), temp=300, count=100, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate forces of base and generated trajectory\n",
    "ml_images = ase.io.read(label+\".traj\", \":\")\n",
    "emt_energy, ml_apparent_energy, ml_actual_energy = calculate_energies(images, ml_images)\n",
    "emt_forces, ml_apparent_forces, ml_actual_forces = calculate_forces(images, ml_images, type=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Plots\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "time_plots(emt_energy, [ml_actual_energy], None, ['ML-LJ'], 'energy', None )\n",
    "time_plots(emt_forces, [ml_actual_forces], None, ['ML-LJ'], 'forces', None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_plots(emt_forces, [ml_apparent_forces, ml_actual_forces] , ['ML-LJ apparent', 'ML-LJ actual'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Resample MD Simulation\n",
    "import random\n",
    "import copy\n",
    "sample_points = random.sample(range(1, len(ml_images)), 10) #sample 10 points\n",
    "images = ase.io.read(\"../../datasets/COCu/COCu_pbc_300K.traj\", \":100\")\n",
    "resampled_images = copy.copy(images)\n",
    "for i in sample_points:\n",
    "    ml_image = ml_images[i].copy()\n",
    "    ml_image.set_calculator(EMT())\n",
    "    resampled_images.append(ml_image)\n",
    "\n",
    "# Define Training data\n",
    "label = \"skorch_resample\"\n",
    "lj_data = lj_optimization(resampled_images, Gs, label)\n",
    "forcetraining = True\n",
    "training_data = AtomsDataset(images, Gaussian, Gs, forcetraining=forcetraining,\n",
    "        label=label, cores=1, lj_data=lj_data)\n",
    "scalings = training_data.scalings\n",
    "unique_atoms = training_data.elements\n",
    "fp_length = training_data.fp_length\n",
    "device = \"cpu\"\n",
    "\n",
    "# Train\n",
    "net = NeuralNetRegressor(\n",
    "    module=FullNN(unique_atoms, [fp_length, 30, 30], device, forcetraining=forcetraining),\n",
    "    criterion=CustomLoss,\n",
    "    criterion__force_coefficient=0.3,\n",
    "    optimizer=torch.optim.Adam,\n",
    "    lr=1e-2,\n",
    "    batch_size=400,\n",
    "    max_epochs=500,\n",
    "    iterator_train__collate_fn=collate_amp,\n",
    "    iterator_valid__collate_fn=collate_amp,\n",
    "    device=device,\n",
    "    train_split=CVSplit(0.1),\n",
    "    callbacks=[\n",
    "        EpochScoring(\n",
    "            forces_score,\n",
    "            on_train=True,\n",
    "            use_caching=True,\n",
    "            target_extractor=target_extractor,\n",
    "        ),\n",
    "        EpochScoring(\n",
    "            energy_score,\n",
    "            on_train=True,\n",
    "            use_caching=True,\n",
    "            target_extractor=target_extractor,\n",
    "        ),\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Define calculator and train\n",
    "calc = AMP(training_data, net, label=label)\n",
    "calc.train(overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MD Simulation\n",
    "md_run(calc=calc, starting_image=images[0].copy(), temp=300, count=100, label=label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate forces of base and generated trajectory\n",
    "ml_resample_images = ase.io.read(label+\".traj\", \":\")\n",
    "emt_energy, ml_r_apparent_energy, ml_r_actual_energy = calculate_energies(images, ml_resample_images)\n",
    "emt_forces, ml_r_apparent_forces, ml_r_actual_forces = calculate_forces(images, ml_resample_images, type=\"max\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time Plots\n",
    "\n",
    "time_plots(emt_energy, [ml_actual_energy, ml_r_actual_energy], None, ['ML-LJ', 'ML-LJ resample'], 'energy', None )\n",
    "time_plots(emt_forces, [ml_actual_forces, ml_r_actual_forces], None, ['ML-LJ', 'ML-LJ resample'], 'forces', None )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kde_plots(emt_forces, [ml_actual_forces, ml_r_actual_forces] , ['ML-LJ', 'ML-LJ resample'])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
