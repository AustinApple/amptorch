Tue Mar 10 18:46:47 2020
--------------------------------------------------
LJ-Parameter Optimization
inital LJ parameter guess [sig, eps]: {'C': [1.0, 6.3535], 'O': [1.0808, 8.5357], 'Cu': [2.1717, 3.7575]}
Optimizer results: 
 fun: 0.8474132279568002 
 message: Max. number of function evaluations reached 
 nfev: 100 
 nit: 16 
 success: False
Fitted LJ parameters: {'C': array([1.        , 0.01931973]), 'O': array([1.        , 1.67213879]), 'Cu': array([1.69902562, 2.12013776])} 

a: 8.868894736303945
Optimization time: 1233.6079456806183 

Filename: COCu_rep_newfit_f100_LJ_100_iter_3
Dataset size: 400
Target scaling: [8.841315589518457, 6.598726145334873]
Symmetry function parameters:
     G2_etas: [0.05       0.23207944 1.07721735 5.        ]
     G2_rs_s: [0, 0, 0, 0]
     G4_etas: [0.005, 0.01]
     G4_zetas: [1.0, 4.0]
     G4_gammas: [1.0, -1]
     cutoff: 5.876798323827276
Device: cpu
Model: FullNN(
  (elementwise_models): ModuleDict(
    (Cu): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=60, out_features=20, bias=True)
        (1): Tanh()
        (2): Linear(in_features=20, out_features=20, bias=True)
        (3): Tanh()
        (4): Linear(in_features=20, out_features=1, bias=True)
      )
    )
    (O): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=60, out_features=20, bias=True)
        (1): Tanh()
        (2): Linear(in_features=20, out_features=20, bias=True)
        (3): Tanh()
        (4): Linear(in_features=20, out_features=1, bias=True)
      )
    )
    (C): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=60, out_features=20, bias=True)
        (1): Tanh()
        (2): Linear(in_features=20, out_features=20, bias=True)
        (3): Tanh()
        (4): Linear(in_features=20, out_features=1, bias=True)
      )
    )
  )
)
Architecture:
   Input Layer - 60
   # of Hidden Layers - 2
   Nodes/Layer - 20
Loss Function: <class 'amptorch.model.CustomLoss'>
Force coefficient: 0.04
Optimizer: <class 'torch.optim.lbfgs.LBFGS'>
Learning Rate: 0.1
Batch Size: 400
Epochs: 200
Shuffle: False
Train Split (k-fold if int, fraction if float): 5

Training initiated...
Epoch   EnergyRMSE    ForceRMSE    TrainLoss    ValidLoss     Dur
===== ============ ============ ============ ============ =======
    1       0.0242       0.3195      30.8099       0.1867 38.8416
    2       0.0129       0.2702       5.0857       0.1235 35.4915
    3       0.0044       0.2796       4.1546       0.1259 36.0254
    4       0.0044       0.2010       2.7360       0.0654 34.5409
    5       0.0124       0.1088       2.0162       0.0251 39.0611
    6       0.0036       0.0993       1.6320       0.0163 41.3830
    7       0.0065       0.0940       1.3292       0.0158 39.2423
    8       0.0035       0.0893       1.0351       0.0132 38.5409
    9       0.0020       0.0973       0.8920       0.0153 39.1990
   10       0.0025       0.0926       0.8052       0.0140 40.8550
   11       0.0030       0.0889       0.7337       0.0130 45.2330
   12       0.0024       0.0866       0.6774       0.0122 46.7372
   13       0.0016       0.0884       0.6394       0.0126 36.2236
   14       0.0026       0.0840       0.5990       0.0116 30.0400
   15       0.0032       0.0860       0.5694       0.0122 30.5207
   16       0.0042       0.0828       0.5364       0.0117 30.1516
   17       0.0012       0.0818       0.5036       0.0108 31.4617
   18       0.0020       0.0806       0.4769       0.0105 30.5797
   19       0.0024       0.0803       0.4471       0.0105 30.1547
   20       0.0018       0.0760       0.4264       0.0094 29.8501
   21       0.0027       0.0791       0.4059       0.0103 32.1280
   22       0.0021       0.0719       0.3850       0.0085 38.7076
   23       0.0023       0.0664       0.3568       0.0073 33.8182
   24       0.0013       0.0646       0.3268       0.0068 34.7612
   25       0.0024       0.0654       0.2965       0.0071 35.1164
   26       0.0008       0.0632       0.2796       0.0064 33.1132
   27       0.0005       0.0658       0.2614       0.0069 34.9088
   28       0.0004       0.0639       0.2513       0.0066 33.7409
   29       0.0007       0.0633       0.2447       0.0064 33.6832
   30       0.0008       0.0611       0.2353       0.0060 33.0913
   31       0.0010       0.0605       0.2289       0.0059 34.3457
   32       0.0005       0.0608       0.2225       0.0059 34.7972
   33       0.0012       0.0594       0.2188       0.0057 33.5727
   34       0.0017       0.0581       0.2145       0.0055 34.1463
   35       0.0005       0.0587       0.2088       0.0055 34.7738
   36       0.0007       0.0583       0.2011       0.0055 35.2987
   37       0.0011       0.0577       0.1983       0.0054 34.9728
   38       0.0009       0.0585       0.1933       0.0055 35.0605
   39       0.0006       0.0610       0.1885       0.0060 33.8941
   40       0.0007       0.0589       0.1854       0.0056 35.0756
   41       0.0007       0.0596       0.1822       0.0057 33.5816
   42       0.0010       0.0591       0.1786       0.0056 33.8251
   43       0.0006       0.0578       0.1750       0.0054 33.5842
   44       0.0006       0.0556       0.1729       0.0050 34.6636
   45       0.0007       0.0541       0.1699       0.0047 34.6655
   46       0.0007       0.0540       0.1672       0.0047 33.7978
   47       0.0010       0.0516       0.1634       0.0043 31.7707
   48       0.0021       0.0510       0.1624       0.0043 31.9464
   49       0.0015       0.0495       0.1604       0.0040 30.5373
   50       0.0022       0.0484       0.1567       0.0039 30.4795
   51       0.0019       0.0483       0.1550       0.0039 30.4413
   52       0.0017       0.0453       0.1536       0.0034 32.1817
   53       0.0019       0.0426       0.1519       0.0031 31.8698
   54       0.0019       0.0418       0.1507       0.0029 30.5610
   55       0.0023       0.0413       0.1495       0.0029 31.5193
   56       0.0019       0.0411       0.1480       0.0029 30.5803
   57       0.0017       0.0411       0.1454       0.0028 30.3904
   58       0.0015       0.0412       0.1443       0.0028 31.4751
   59       0.0014       0.0394       0.1427       0.0026 30.6759
   60       0.0020       0.0400       0.1415       0.0027 31.5658
   61       0.0017       0.0372       0.1403       0.0023 29.8202
   62       0.0009       0.0364       0.1380       0.0021 27.9921
   63       0.0015       0.0316       0.1373       0.0017 27.6294
   64       0.0012       0.0315       0.1349       0.0016 27.9716
   65       0.0013       0.0325       0.1336       0.0018 27.7992
   66       0.0007       0.0327       0.1325       0.0017 26.3112
   67       0.0007       0.0311       0.1309       0.0016 26.4704
   68       0.0008       0.0319       0.1295       0.0017 26.5585
   69       0.0010       0.0312       0.1283       0.0016 27.4000
   70       0.0009       0.0313       0.1271       0.0016 26.0296
   71       0.0009       0.0297       0.1262       0.0014 27.1129
   72       0.0009       0.0293       0.1254       0.0014 27.2236
   73       0.0014       0.0281       0.1249       0.0013 25.9892
   74       0.0012       0.0284       0.1236       0.0013 25.9799
   75       0.0013       0.0287       0.1229       0.0014 27.2026
   76       0.0010       0.0295       0.1222       0.0014 25.8642
   77       0.0008       0.0298       0.1212       0.0014 27.0071
   78       0.0009       0.0306       0.1201       0.0015 27.1646
   79       0.0007       0.0298       0.1191       0.0014 26.1429
   80       0.0004       0.0304       0.1180       0.0015 25.9740
   81       0.0006       0.0297       0.1167       0.0014 25.9547
   82       0.0004       0.0297       0.1160       0.0014 26.0694
   83       0.0004       0.0294       0.1144       0.0014 25.8752
   84       0.0005       0.0300       0.1131       0.0014 27.1132
   85       0.0003       0.0306       0.1121       0.0015 26.0181
   86       0.0002       0.0297       0.1107       0.0014 26.0107
   87       0.0003       0.0295       0.1097       0.0014 26.8605
   88       0.0007       0.0278       0.1086       0.0013 25.7683
   89       0.0006       0.0268       0.1077       0.0012 25.7475
   90       0.0006       0.0264       0.1066       0.0011 26.7507
   91       0.0007       0.0258       0.1056       0.0011 24.5811
   92       0.0005       0.0252       0.1047       0.0010 25.3969
   93       0.0007       0.0243       0.1037       0.0010 24.4111
   94       0.0010       0.0229       0.1025       0.0009 24.3030
   95       0.0005       0.0234       0.1010       0.0009 24.4209
   96       0.0010       0.0227       0.1000       0.0009 28.7019
   97       0.0008       0.0232       0.0990       0.0009 27.3790
   98       0.0007       0.0236       0.0983       0.0009 25.2660
   99       0.0010       0.0231       0.0977       0.0009 25.4529
  100       0.0012       0.0227       0.0971       0.0009 26.5854
  101       0.0018       0.0225       0.0959       0.0009 25.5522
  102       0.0023       0.0226       0.0947       0.0010 26.5555
  103       0.0018       0.0229       0.0939       0.0010 26.5762
  104       0.0019       0.0237       0.0934       0.0010 26.7073
  105       0.0020       0.0230       0.0929       0.0010 32.1760
  106       0.0016       0.0225       0.0915       0.0009 26.7872
  107       0.0013       0.0240       0.0905       0.0010 26.8879
  108       0.0013       0.0242       0.0899       0.0010 28.1112
  109       0.0014       0.0238       0.0891       0.0010 27.2770
  110       0.0011       0.0242       0.0886       0.0010 27.0767
  111       0.0015       0.0249       0.0883       0.0011 27.1773
  112       0.0020       0.0258       0.0876       0.0012 27.1876
  113       0.0011       0.0252       0.0871       0.0011 26.9023
  114       0.0011       0.0253       0.0866       0.0011 28.2486
  115       0.0010       0.0255       0.0862       0.0011 27.2753
  116       0.0014       0.0267       0.0858       0.0012 27.4461
  117       0.0011       0.0264       0.0854       0.0012 27.0807
  118       0.0014       0.0260       0.0849       0.0012 27.3840
  119       0.0012       0.0264       0.0845       0.0012 27.1655
  120       0.0011       0.0252       0.0843       0.0011 28.3408
  121       0.0013       0.0247       0.0840       0.0011 28.3524
  122       0.0012       0.0242       0.0837       0.0010 28.4214
  123       0.0008       0.0239       0.0834       0.0009 27.0445
  124       0.0007       0.0219       0.0831       0.0008 27.1408
  125       0.0008       0.0214       0.0826       0.0008 28.1378
  126       0.0010       0.0212       0.0822       0.0008 27.5317
  127       0.0008       0.0212       0.0819       0.0007 28.3786
  128       0.0004       0.0203       0.0816       0.0007 28.3971
  129       0.0005       0.0202       0.0812       0.0007 28.3727
  130       0.0007       0.0202       0.0810       0.0007 27.4354
  131       0.0005       0.0201       0.0809       0.0007 28.2669
  132       0.0003       0.0196       0.0807       0.0006 27.3117
  133       0.0004       0.0200       0.0804       0.0006 27.0534
  134       0.0006       0.0199       0.0803       0.0006 28.3511
  135       0.0005       0.0198       0.0802       0.0006 33.3786
  136       0.0003       0.0197       0.0801       0.0006 28.2589
  137       0.0006       0.0198       0.0799       0.0006 29.3879
  138       0.0004       0.0202       0.0798       0.0007 29.6956
  139       0.0005       0.0202       0.0796       0.0007 30.6214
  140       0.0006       0.0200       0.0794       0.0007 29.4357
  141       0.0004       0.0210       0.0791       0.0007 29.5013
  142       0.0005       0.0201       0.0788       0.0007 30.9079
  143       0.0002       0.0197       0.0786       0.0006 30.9020
  144       0.0006       0.0191       0.0784       0.0006 29.4275
  145       0.0004       0.0196       0.0782       0.0006 30.3597
  146       0.0004       0.0189       0.0779       0.0006 30.7642
  147       0.0005       0.0192       0.0776       0.0006 29.4027
  148       0.0006       0.0193       0.0775       0.0006 30.5124
  149       0.0005       0.0191       0.0773       0.0006 29.3933
  150       0.0004       0.0194       0.0772       0.0006 29.4257
  151       0.0004       0.0190       0.0771       0.0006 29.4963
  152       0.0007       0.0190       0.0769       0.0006 29.6372
  153       0.0005       0.0191       0.0768       0.0006 29.4739
  154       0.0007       0.0190       0.0765       0.0006 29.4749
  155       0.0007       0.0184       0.0764       0.0006 29.6277
  156       0.0005       0.0184       0.0762       0.0006 31.1659
  157       0.0006       0.0186       0.0761       0.0006 29.8592
  158       0.0004       0.0192       0.0759       0.0006 31.0204
  159       0.0005       0.0192       0.0757       0.0006 31.1479
  160       0.0007       0.0191       0.0756       0.0006 30.9001
  161       0.0007       0.0190       0.0754       0.0006 30.1101
  162       0.0007       0.0187       0.0752       0.0006 31.0500
  163       0.0007       0.0186       0.0750       0.0006 29.9857
  164       0.0007       0.0186       0.0747       0.0006 30.8115
  165       0.0007       0.0185       0.0746       0.0006 29.8712
  166       0.0006       0.0185       0.0744       0.0006 31.7869
  167       0.0005       0.0189       0.0742       0.0006 36.7431
  168       0.0004       0.0189       0.0740       0.0006 33.2073
  169       0.0003       0.0190       0.0739       0.0006 29.9262
  170       0.0004       0.0192       0.0737       0.0006 30.1515
  171       0.0003       0.0195       0.0736       0.0006 31.8805
  172       0.0004       0.0195       0.0735       0.0006 30.0717
  173       0.0003       0.0195       0.0734       0.0006 31.6796
  174       0.0003       0.0198       0.0732       0.0006 30.9165
  175       0.0005       0.0205       0.0731       0.0007 28.6940
  176       0.0007       0.0200       0.0729       0.0007 28.0795
  177       0.0008       0.0200       0.0727       0.0007 28.1594
  178       0.0008       0.0202       0.0725       0.0007 27.8496
  179       0.0008       0.0205       0.0724       0.0007 27.4122
  180       0.0008       0.0207       0.0723       0.0007 27.3935
  181       0.0006       0.0211       0.0721       0.0007 28.9222
  182       0.0006       0.0211       0.0720       0.0007 28.2488
  183       0.0007       0.0210       0.0717       0.0007 27.5389
  184       0.0006       0.0209       0.0716       0.0007 27.1582
  185       0.0007       0.0212       0.0715       0.0007 27.4304
  186       0.0007       0.0209       0.0714       0.0007 27.5194
  187       0.0007       0.0204       0.0713       0.0007 27.5704
  188       0.0007       0.0203       0.0711       0.0007 28.3873
  189       0.0008       0.0205       0.0709       0.0007 27.2928
  190       0.0009       0.0208       0.0708       0.0007 27.2998
  191       0.0007       0.0206       0.0707       0.0007 28.5824
  192       0.0009       0.0208       0.0706       0.0007 27.5274
  193       0.0009       0.0200       0.0703       0.0007 28.8160
  194       0.0008       0.0206       0.0701       0.0007 27.0001
  195       0.0005       0.0203       0.0699       0.0007 27.2490
  196       0.0004       0.0200       0.0697       0.0006 28.4707
  197       0.0004       0.0205       0.0695       0.0007 26.9240
  198       0.0006       0.0204       0.0694       0.0007 27.5369
  199       0.0004       0.0201       0.0693       0.0007 27.3948
  200       0.0003       0.0202       0.0690       0.0007 27.5007
...Training Complete!

