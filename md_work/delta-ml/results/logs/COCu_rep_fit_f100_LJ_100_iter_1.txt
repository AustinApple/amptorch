Tue Mar 10 14:23:23 2020
--------------------------------------------------
LJ-Parameter Optimization
inital LJ parameter guess [sig, eps]: {'C': [1.0, 6.3535], 'O': [1.0808, 8.5357], 'Cu': [2.1717, 3.7575]}
Optimizer results: 
 fun: 0.17137304630162867 
 message: Maximum number of function evaluations has been exceeded. 
 nfev: 1400 
 nit: 915 
 success: False
Fitted LJ parameters: {'C': array([ 0.14397258, 17.50873356]), 'O': array([ 0.65055142, 19.38705907]), 'Cu': array([1.82483391, 0.00330646])} 

a: 6.096807230838781
Optimization time: 979.8291175365448 

Filename: COCu_rep_fit_f100_LJ_100_iter_1
Dataset size: 200
Target scaling: [8.841315589518457, 2.320395382128714]
Symmetry function parameters:
     G2_etas: [0.05       0.23207944 1.07721735 5.        ]
     G2_rs_s: [0, 0, 0, 0]
     G4_etas: [0.005, 0.01]
     G4_zetas: [1.0, 4.0]
     G4_gammas: [1.0, -1]
     cutoff: 5.876798323827276
Device: cpu
Model: FullNN(
  (elementwise_models): ModuleDict(
    (Cu): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=60, out_features=20, bias=True)
        (1): Tanh()
        (2): Linear(in_features=20, out_features=20, bias=True)
        (3): Tanh()
        (4): Linear(in_features=20, out_features=1, bias=True)
      )
    )
    (O): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=60, out_features=20, bias=True)
        (1): Tanh()
        (2): Linear(in_features=20, out_features=20, bias=True)
        (3): Tanh()
        (4): Linear(in_features=20, out_features=1, bias=True)
      )
    )
    (C): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=60, out_features=20, bias=True)
        (1): Tanh()
        (2): Linear(in_features=20, out_features=20, bias=True)
        (3): Tanh()
        (4): Linear(in_features=20, out_features=1, bias=True)
      )
    )
  )
)
Architecture:
   Input Layer - 60
   # of Hidden Layers - 2
   Nodes/Layer - 20
Loss Function: <class 'amptorch.model.CustomLoss'>
Force coefficient: 0.04
Optimizer: <class 'torch.optim.lbfgs.LBFGS'>
Learning Rate: 0.1
Batch Size: 200
Epochs: 200
Shuffle: False
Train Split (k-fold if int, fraction if float): 5

Training initiated...
Epoch   EnergyRMSE    ForceRMSE    TrainLoss    ValidLoss     Dur
===== ============ ============ ============ ============ =======
    1       0.0050       0.2343       1.5468       0.0444 13.8866
    2       0.0090       0.2056       0.6214       0.0354 13.8533
    3       0.0037       0.2178       0.5868       0.0382 14.5374
    4       0.0060       0.2159       0.5291       0.0380 13.9998
    5       0.0074       0.1764       0.4908       0.0260 14.5923
    6       0.0031       0.1861       0.4283       0.0279 14.4961
    7       0.0032       0.1668       0.4056       0.0225 14.0269
    8       0.0021       0.1650       0.3867       0.0219 14.0104
    9       0.0009       0.1535       0.3674       0.0189 14.5524
   10       0.0009       0.1560       0.3478       0.0195 14.4876
   11       0.0009       0.1556       0.3369       0.0194 14.4536
   12       0.0008       0.1574       0.3295       0.0198 13.9297
   13       0.0018       0.1480       0.3192       0.0176 14.5199
   14       0.0009       0.1460       0.3086       0.0171 14.5989
   15       0.0011       0.1435       0.3026       0.0165 14.0973
   16       0.0013       0.1425       0.2929       0.0163 14.0472
   17       0.0017       0.1419       0.2844       0.0162 13.8702
   18       0.0009       0.1398       0.2808       0.0156 14.0440
   19       0.0014       0.1381       0.2747       0.0153 13.8227
   20       0.0010       0.1357       0.2699       0.0147 17.5723
   21       0.0010       0.1328       0.2624       0.0141 16.4913
   22       0.0012       0.1308       0.2579       0.0137 14.4236
   23       0.0012       0.1274       0.2546       0.0130 13.8699
   24       0.0010       0.1246       0.2505       0.0124 14.3473
   25       0.0020       0.1195       0.2468       0.0115 13.8900
   26       0.0017       0.1175       0.2396       0.0111 14.5533
   27       0.0011       0.1136       0.2352       0.0103 13.9669
   28       0.0018       0.1075       0.2320       0.0093 14.0948
   29       0.0026       0.1009       0.2277       0.0083 14.5410
   30       0.0023       0.0954       0.2227       0.0074 14.5323
   31       0.0022       0.0870       0.2183       0.0061 14.4324
   32       0.0030       0.0849       0.2139       0.0060 14.4390
   33       0.0023       0.0858       0.2108       0.0060 14.0052
   34       0.0014       0.0795       0.2078       0.0051 13.9726
   35       0.0008       0.0709       0.2047       0.0040 14.5493
   36       0.0005       0.0680       0.2018       0.0037 13.9460
   37       0.0021       0.0720       0.1977       0.0042 14.0093
   38       0.0006       0.0784       0.1947       0.0049 14.5519
   39       0.0007       0.0777       0.1931       0.0048 14.0375
   40       0.0007       0.0741       0.1916       0.0044 15.6829
   41       0.0009       0.0639       0.1884       0.0033 18.0080
   42       0.0004       0.0621       0.1857       0.0031 13.8973
   43       0.0006       0.0539       0.1837       0.0023 13.8607
   44       0.0006       0.0514       0.1798       0.0021 14.5109
   45       0.0005       0.0485       0.1762       0.0019 17.7134
   46       0.0007       0.0538       0.1738       0.0023 13.9988
   47       0.0007       0.0539       0.1697       0.0023 13.6583
   48       0.0017       0.0608       0.1671       0.0030 20.1312
   49       0.0012       0.0676       0.1630       0.0037 14.6227
   50       0.0012       0.0600       0.1612       0.0029 13.8173
   51       0.0014       0.0621       0.1566       0.0031 14.0940
   52       0.0012       0.0607       0.1543       0.0030 13.8643
   53       0.0013       0.0613       0.1521       0.0030 14.1138
   54       0.0015       0.0592       0.1491       0.0028 16.2944
   55       0.0020       0.0587       0.1462       0.0028 16.4467
   56       0.0016       0.0601       0.1435       0.0029 13.3115
   57       0.0008       0.0537       0.1420       0.0023 13.2059
   58       0.0012       0.0563       0.1396       0.0026 13.6322
   59       0.0010       0.0524       0.1362       0.0022 13.5861
   60       0.0007       0.0523       0.1325       0.0022 13.5784
   61       0.0009       0.0535       0.1309       0.0023 13.5280
   62       0.0019       0.0500       0.1288       0.0021 13.1173
   63       0.0021       0.0551       0.1261       0.0025 13.5091
   64       0.0014       0.0512       0.1230       0.0021 13.6276
   65       0.0012       0.0521       0.1224       0.0022 13.1571
   66       0.0007       0.0506       0.1204       0.0021 13.6056
   67       0.0016       0.0482       0.1191       0.0019 13.0886
   68       0.0009       0.0491       0.1175       0.0019 12.9493
   69       0.0007       0.0513       0.1158       0.0021 13.1597
   70       0.0007       0.0470       0.1141       0.0018 13.6145
   71       0.0006       0.0485       0.1124       0.0019 13.6616
   72       0.0007       0.0494       0.1102       0.0020 13.7207
   73       0.0011       0.0495       0.1088       0.0020 13.2121
   74       0.0009       0.0487       0.1078       0.0019 13.8560
   75       0.0009       0.0473       0.1067       0.0018 13.0626
   76       0.0012       0.0465       0.1056       0.0018 13.2451
   77       0.0013       0.0455       0.1048       0.0017 13.0282
   78       0.0008       0.0455       0.1036       0.0017 13.0784
   79       0.0005       0.0444       0.1027       0.0016 13.6082
   80       0.0005       0.0440       0.1020       0.0016 22.5699
   81       0.0007       0.0410       0.1011       0.0014 15.5704
   82       0.0006       0.0406       0.1001       0.0013 21.8120
   83       0.0004       0.0409       0.0995       0.0013 13.7506
   84       0.0005       0.0413       0.0991       0.0014 17.6911
   85       0.0005       0.0403       0.0985       0.0013 13.8113
   86       0.0006       0.0392       0.0978       0.0012 13.1829
   87       0.0004       0.0387       0.0975       0.0012 13.0731
   88       0.0007       0.0404       0.0969       0.0013 13.3281
   89       0.0005       0.0408       0.0962       0.0013 15.8049
   90       0.0009       0.0401       0.0957       0.0013 21.6737
   91       0.0007       0.0392       0.0952       0.0012 19.9990
   92       0.0009       0.0395       0.0946       0.0013 16.0094
   93       0.0005       0.0385       0.0943       0.0012 13.6533
   94       0.0008       0.0375       0.0936       0.0011 13.1879
   95       0.0007       0.0377       0.0930       0.0011 13.6394
   96       0.0009       0.0392       0.0927       0.0012 18.1687
   97       0.0006       0.0379       0.0926       0.0012 16.1268
   98       0.0006       0.0370       0.0921       0.0011 13.8899
   99       0.0005       0.0360       0.0919       0.0010 13.4108
  100       0.0006       0.0358       0.0916       0.0010 14.0374
  101       0.0009       0.0364       0.0912       0.0011 14.6106
  102       0.0008       0.0372       0.0909       0.0011 14.6613
  103       0.0009       0.0380       0.0904       0.0012 14.9751
  104       0.0009       0.0388       0.0900       0.0012 14.7402
  105       0.0008       0.0389       0.0898       0.0012 13.9740
  106       0.0013       0.0406       0.0895       0.0014 14.4520
  107       0.0010       0.0406       0.0890       0.0013 14.0210
  108       0.0008       0.0430       0.0887       0.0015 14.0110
  109       0.0011       0.0441       0.0883       0.0016 13.9635
  110       0.0009       0.0438       0.0880       0.0016 14.6631
  111       0.0008       0.0438       0.0878       0.0015 14.3982
  112       0.0008       0.0426       0.0873       0.0015 13.9825
  113       0.0006       0.0407       0.0869       0.0013 14.5737
  114       0.0005       0.0415       0.0866       0.0014 14.5676
  115       0.0006       0.0414       0.0860       0.0014 14.2212
  116       0.0006       0.0399       0.0858       0.0013 14.4860
  117       0.0006       0.0397       0.0855       0.0013 14.3693
  118       0.0007       0.0406       0.0851       0.0013 14.0110
  119       0.0007       0.0393       0.0849       0.0012 13.9368
  120       0.0005       0.0396       0.0845       0.0013 13.9540
  121       0.0005       0.0388       0.0842       0.0012 13.9010
  122       0.0005       0.0403       0.0839       0.0013 13.9879
  123       0.0004       0.0388       0.0837       0.0012 14.4563
  124       0.0004       0.0404       0.0834       0.0013 14.0246
  125       0.0004       0.0416       0.0831       0.0014 14.4879
  126       0.0005       0.0398       0.0829       0.0013 13.9316
  127       0.0003       0.0383       0.0826       0.0012 13.9839
  128       0.0004       0.0374       0.0823       0.0011 14.0010
  129       0.0005       0.0360       0.0821       0.0010 14.4510
  130       0.0004       0.0386       0.0818       0.0012 14.5956
  131       0.0003       0.0399       0.0814       0.0013 13.9867
  132       0.0004       0.0391       0.0812       0.0012 14.0369
  133       0.0002       0.0424       0.0810       0.0014 14.4966
  134       0.0002       0.0425       0.0806       0.0014 14.4609
  135       0.0004       0.0415       0.0805       0.0014 13.9904
  136       0.0004       0.0406       0.0803       0.0013 14.5374
  137       0.0005       0.0400       0.0801       0.0013 14.5515
  138       0.0004       0.0405       0.0799       0.0013 13.9262
  139       0.0005       0.0397       0.0797       0.0013 14.5780
  140       0.0006       0.0389       0.0796       0.0012 14.5561
  141       0.0006       0.0408       0.0793       0.0013 14.5342
  142       0.0003       0.0417       0.0792       0.0014 14.5591
  143       0.0005       0.0427       0.0790       0.0015 13.9794
  144       0.0005       0.0421       0.0788       0.0014 14.5437
  145       0.0005       0.0409       0.0786       0.0013 14.3119
  146       0.0005       0.0399       0.0785       0.0013 13.8875
  147       0.0004       0.0396       0.0783       0.0013 14.4541
  148       0.0006       0.0397       0.0779       0.0013 13.9486
  149       0.0007       0.0381       0.0776       0.0012 13.9201
  150       0.0006       0.0391       0.0774       0.0012 14.3989
  151       0.0004       0.0398       0.0772       0.0013 13.9870
  152       0.0005       0.0396       0.0771       0.0013 13.9446
  153       0.0003       0.0398       0.0768       0.0013 14.5482
  154       0.0003       0.0363       0.0767       0.0011 14.0529
  155       0.0002       0.0367       0.0765       0.0011 13.9698
  156       0.0003       0.0368       0.0763       0.0011 14.5511
  157       0.0002       0.0393       0.0760       0.0012 13.9942
  158       0.0003       0.0387       0.0758       0.0012 13.8777
  159       0.0003       0.0383       0.0756       0.0012 14.5154
  160       0.0004       0.0374       0.0754       0.0011 14.0714
  161       0.0005       0.0381       0.0751       0.0012 22.6564
  162       0.0004       0.0363       0.0750       0.0011 22.9502
  163       0.0005       0.0362       0.0748       0.0011 18.6267
  164       0.0003       0.0337       0.0746       0.0009 14.0076
  165       0.0003       0.0314       0.0744       0.0008 14.1980
  166       0.0004       0.0305       0.0742       0.0007 13.9996
  167       0.0005       0.0298       0.0740       0.0007 14.2016
  168       0.0005       0.0299       0.0737       0.0007 14.6085
  169       0.0004       0.0310       0.0736       0.0008 14.5373
  170       0.0003       0.0329       0.0734       0.0009 14.0053
  171       0.0002       0.0339       0.0732       0.0009 17.5105
  172       0.0002       0.0346       0.0731       0.0010 17.0007
  173       0.0002       0.0342       0.0729       0.0009 14.4101
  174       0.0003       0.0345       0.0727       0.0010 16.4072
  175       0.0001       0.0353       0.0725       0.0010 15.6838
  176       0.0001       0.0351       0.0724       0.0010 16.2816
  177       0.0003       0.0351       0.0722       0.0010 16.0857
  178       0.0002       0.0339       0.0719       0.0009 16.5041
  179       0.0004       0.0344       0.0716       0.0010 16.1585
  180       0.0003       0.0338       0.0714       0.0009 16.1015
  181       0.0004       0.0334       0.0711       0.0009 16.2944
  182       0.0004       0.0328       0.0710       0.0009 15.7388
  183       0.0004       0.0341       0.0708       0.0009 16.3150
  184       0.0005       0.0333       0.0707       0.0009 15.7103
  185       0.0002       0.0335       0.0705       0.0009 16.0351
  186       0.0002       0.0346       0.0703       0.0010 15.8186
  187       0.0004       0.0343       0.0701       0.0009 16.2284
  188       0.0002       0.0354       0.0699       0.0010 16.2937
  189       0.0003       0.0354       0.0697       0.0010 16.6059
  190       0.0003       0.0348       0.0696       0.0010 16.3106
  191       0.0003       0.0350       0.0694       0.0010 15.0954
  192       0.0003       0.0336       0.0693       0.0009 14.9174
  193       0.0003       0.0345       0.0690       0.0010 16.7417
  194       0.0004       0.0344       0.0689       0.0010 16.3536
  195       0.0003       0.0360       0.0688       0.0010 15.8521
  196       0.0002       0.0382       0.0686       0.0012 15.7576
  197       0.0002       0.0392       0.0685       0.0012 16.6777
  198       0.0001       0.0397       0.0684       0.0013 16.1688
  199       0.0002       0.0387       0.0682       0.0012 16.6936
  200       0.0001       0.0404       0.0680       0.0013 16.6928
...Training Complete!

