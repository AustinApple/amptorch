Fri Mar 13 01:20:28 2020
--------------------------------------------------
LJ-Parameter Optimization
inital LJ parameter guess [sig, eps]: {'C': [0.972, 6.379, 0.477], 'O': [1.09, 8.575, 0.603], 'Cu': [2.168, 3.8386, 1.696]}
Optimizer results: 
 fun: 10.809068648534671 
 message: Linear search failed 
 nfev: 92 
 nit: 5 
 success: False
Fitted LJ parameters: {'C': array([1.23691023, 3.00776889, 1.        ]), 'O': array([1.43054569, 7.78298302, 1.        ]), 'Cu': array([1.53639021e+00, 1.00000000e-05, 1.38331805e+00])} 

Optimization time: 1180.6279392242432 

Filename: COCu_morse_new_200_5k_LJ_100_iter_1
Dataset size: 300
Target scaling: [8.841315589518457, -3.4844788112662135]
Symmetry function parameters:
     G2_etas: [0.05       0.09653489 0.18637969 0.35984284 0.69474775 1.3413479
 2.58973734 5.        ]
     G2_rs_s: [0, 0, 0, 0, 0, 0, 0, 0]
     G4_etas: [0.005, 0.01]
     G4_zetas: [1.0, 4.0, 6.0]
     G4_gammas: [1.0, -1]
     cutoff: 5.876798323827276
Device: cpu
Model: FullNN(
  (elementwise_models): ModuleDict(
    (Cu): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=96, out_features=30, bias=True)
        (1): Tanh()
        (2): Linear(in_features=30, out_features=30, bias=True)
        (3): Tanh()
        (4): Linear(in_features=30, out_features=30, bias=True)
        (5): Tanh()
        (6): Linear(in_features=30, out_features=1, bias=True)
      )
    )
    (O): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=96, out_features=30, bias=True)
        (1): Tanh()
        (2): Linear(in_features=30, out_features=30, bias=True)
        (3): Tanh()
        (4): Linear(in_features=30, out_features=30, bias=True)
        (5): Tanh()
        (6): Linear(in_features=30, out_features=1, bias=True)
      )
    )
    (C): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=96, out_features=30, bias=True)
        (1): Tanh()
        (2): Linear(in_features=30, out_features=30, bias=True)
        (3): Tanh()
        (4): Linear(in_features=30, out_features=30, bias=True)
        (5): Tanh()
        (6): Linear(in_features=30, out_features=1, bias=True)
      )
    )
  )
)
Architecture:
   Input Layer - 96
   # of Hidden Layers - 3
   Nodes/Layer - 30
Loss Function: <class 'amptorch.model.CustomLoss'>
Force coefficient: 0.04
Optimizer: <class 'torch.optim.lbfgs.LBFGS'>
Learning Rate: 0.1
Batch Size: 300
Epochs: 200
Shuffle: False
Train Split (k-fold if int, fraction if float): 5

Training initiated...
Epoch   EnergyRMSE    ForceRMSE    TrainLoss    ValidLoss     Dur
===== ============ ============ ============ ============ =======
    1       0.1671       3.0163      47.9778      11.7555 26.8860
    2       0.1019       2.0580      32.5930       5.3939 27.9493
    3       0.0368       1.7296       9.6988       3.6305 26.8918
    4       0.0422       1.2316       4.6351       1.8737 27.8140
    5       0.0657       0.9253       2.5916       1.1570 27.7936
    6       0.0252       0.5876       1.6241       0.4334 26.6231
    7       0.0097       0.5324       0.8493       0.3430 27.7653
    8       0.0069       0.3688       0.5946       0.1647 27.8680
    9       0.0067       0.3499       0.4049       0.1483 26.8916
   10       0.0062       0.3319       0.3014       0.1333 26.9338
   11       0.0052       0.2997       0.2548       0.1086 27.7554
   12       0.0061       0.2920       0.2225       0.1034 27.8656
   13       0.0063       0.2457       0.1946       0.0736 26.8284
   14       0.0046       0.2167       0.1794       0.0570 26.7999
   15       0.0032       0.2161       0.1648       0.0564 26.8726
   16       0.0028       0.1969       0.1478       0.0468 27.8201
   17       0.0025       0.1749       0.1297       0.0369 26.9168
   18       0.0030       0.1744       0.1085       0.0368 27.7913
   19       0.0028       0.1527       0.0957       0.0282 26.8478
   20       0.0020       0.1436       0.0858       0.0249 27.9642
   21       0.0023       0.1344       0.0791       0.0218 27.8896
   22       0.0023       0.1285       0.0717       0.0200 28.0001
   23       0.0025       0.1255       0.0676       0.0191 26.7447
   24       0.0019       0.1181       0.0632       0.0169 26.7769
   25       0.0018       0.1184       0.0603       0.0169 27.7112
   26       0.0020       0.1198       0.0566       0.0173 26.8366
   27       0.0017       0.1152       0.0546       0.0160 27.7381
   28       0.0018       0.1081       0.0531       0.0141 26.8132
   29       0.0016       0.1031       0.0502       0.0128 27.1308
   30       0.0018       0.1025       0.0486       0.0127 26.7300
   31       0.0018       0.0985       0.0468       0.0117 26.7847
   32       0.0018       0.0968       0.0449       0.0113 27.8985
   33       0.0018       0.0928       0.0435       0.0104 27.0409
   34       0.0015       0.0888       0.0421       0.0095 27.1374
   35       0.0015       0.0842       0.0411       0.0086 26.9724
   36       0.0012       0.0811       0.0400       0.0079 27.9034
   37       0.0012       0.0783       0.0389       0.0074 26.7615
   38       0.0011       0.0849       0.0381       0.0087 26.7987
   39       0.0010       0.0844       0.0371       0.0086 26.8635
   40       0.0012       0.0845       0.0367       0.0086 26.8073
   41       0.0008       0.0845       0.0356       0.0086 26.7489
   42       0.0008       0.0843       0.0347       0.0085 26.8518
   43       0.0009       0.0873       0.0338       0.0092 26.8450
   44       0.0009       0.0851       0.0329       0.0087 26.6751
   45       0.0011       0.0894       0.0324       0.0096 28.0251
   46       0.0009       0.0894       0.0317       0.0096 26.9130
   47       0.0008       0.0879       0.0312       0.0093 27.2205
   48       0.0009       0.0893       0.0303       0.0096 27.0063
   49       0.0009       0.0906       0.0296       0.0099 28.0314
   50       0.0010       0.0882       0.0290       0.0094 27.1118
   51       0.0009       0.0850       0.0286       0.0087 26.9188
   52       0.0008       0.0802       0.0282       0.0077 27.0472
   53       0.0010       0.0834       0.0277       0.0084 27.0978
   54       0.0007       0.0763       0.0273       0.0070 27.0490
   55       0.0007       0.0744       0.0268       0.0067 27.0005
   56       0.0010       0.0695       0.0265       0.0058 26.8439
   57       0.0007       0.0703       0.0259       0.0059 26.8531
   58       0.0007       0.0682       0.0255       0.0056 27.8182
   59       0.0007       0.0671       0.0252       0.0054 26.7636
   60       0.0007       0.0642       0.0246       0.0050 26.7140
   61       0.0007       0.0619       0.0243       0.0046 26.8299
   62       0.0008       0.0601       0.0241       0.0043 26.9047
   63       0.0007       0.0607       0.0236       0.0044 27.9024
   64       0.0008       0.0593       0.0233       0.0042 27.8832
   65       0.0007       0.0600       0.0230       0.0043 27.8586
   66       0.0006       0.0606       0.0226       0.0044 26.9031
   67       0.0008       0.0617       0.0223       0.0046 27.9579
   68       0.0008       0.0608       0.0217       0.0045 26.8265
   69       0.0008       0.0596       0.0215       0.0043 26.9320
   70       0.0007       0.0586       0.0211       0.0041 26.9807
   71       0.0008       0.0573       0.0207       0.0040 27.0382
   72       0.0009       0.0591       0.0204       0.0042 27.0252
   73       0.0011       0.0598       0.0202       0.0043 26.9956
   74       0.0013       0.0604       0.0199       0.0044 27.3935
   75       0.0011       0.0604       0.0197       0.0044 27.0894
   76       0.0008       0.0626       0.0194       0.0047 26.7913
   77       0.0009       0.0639       0.0190       0.0049 27.9665
   78       0.0009       0.0647       0.0186       0.0051 27.0142
   79       0.0009       0.0666       0.0183       0.0053 27.4626
   80       0.0010       0.0655       0.0181       0.0052 27.2730
   81       0.0007       0.0663       0.0178       0.0053 28.2856
   82       0.0007       0.0624       0.0174       0.0047 27.9152
   83       0.0010       0.0631       0.0171       0.0048 26.9957
   84       0.0008       0.0664       0.0169       0.0053 28.3461
   85       0.0006       0.0633       0.0167       0.0048 28.1054
   86       0.0006       0.0626       0.0166       0.0047 28.0156
   87       0.0006       0.0640       0.0163       0.0049 27.1110
   88       0.0008       0.0653       0.0162       0.0051 28.1463
   89       0.0009       0.0635       0.0159       0.0049 28.2683
   90       0.0008       0.0628       0.0156       0.0048 27.2439
   91       0.0010       0.0613       0.0154       0.0045 27.2261
   92       0.0009       0.0593       0.0152       0.0042 27.2187
   93       0.0008       0.0574       0.0150       0.0040 27.0897
   94       0.0011       0.0569       0.0147       0.0039 28.2193
   95       0.0007       0.0579       0.0145       0.0040 27.1139
   96       0.0008       0.0575       0.0144       0.0040 28.2438
   97       0.0007       0.0578       0.0142       0.0040 27.1645
   98       0.0009       0.0566       0.0141       0.0039 28.3239
   99       0.0009       0.0574       0.0139       0.0040 26.8269
  100       0.0008       0.0570       0.0137       0.0039 27.0397
  101       0.0007       0.0546       0.0135       0.0036 28.1991
  102       0.0008       0.0538       0.0133       0.0035 28.3177
  103       0.0007       0.0525       0.0131       0.0033 27.1765
  104       0.0007       0.0507       0.0130       0.0031 28.1557
  105       0.0006       0.0484       0.0127       0.0028 27.1524
  106       0.0008       0.0498       0.0126       0.0030 27.2685
  107       0.0008       0.0496       0.0123       0.0030 28.2274
  108       0.0007       0.0486       0.0122       0.0028 27.1718
  109       0.0007       0.0480       0.0119       0.0028 28.1719
  110       0.0006       0.0482       0.0117       0.0028 27.9114
  111       0.0006       0.0487       0.0115       0.0029 27.2751
  112       0.0005       0.0479       0.0114       0.0028 27.0819
  113       0.0006       0.0469       0.0112       0.0026 28.1501
  114       0.0005       0.0451       0.0110       0.0024 28.2749
  115       0.0006       0.0442       0.0109       0.0024 27.0861
  116       0.0007       0.0437       0.0107       0.0023 27.2568
  117       0.0006       0.0433       0.0106       0.0023 27.0475
  118       0.0006       0.0431       0.0103       0.0022 28.2040
  119       0.0005       0.0425       0.0102       0.0022 27.2214
  120       0.0006       0.0445       0.0101       0.0024 27.1157
  121       0.0005       0.0445       0.0099       0.0024 28.0790
  122       0.0005       0.0456       0.0098       0.0025 26.8353
  123       0.0005       0.0450       0.0097       0.0024 28.2859
  124       0.0005       0.0450       0.0096       0.0024 27.2446
  125       0.0005       0.0452       0.0095       0.0025 27.0157
  126       0.0005       0.0449       0.0094       0.0024 27.1677
  127       0.0006       0.0458       0.0093       0.0025 26.8456
  128       0.0006       0.0463       0.0091       0.0026 27.9514
  129       0.0005       0.0452       0.0090       0.0025 26.8706
  130       0.0005       0.0458       0.0089       0.0025 26.6921
  131       0.0005       0.0456       0.0089       0.0025 26.9187
  132       0.0005       0.0461       0.0087       0.0026 26.8607
  133       0.0007       0.0461       0.0087       0.0026 26.8711
  134       0.0008       0.0457       0.0085       0.0025 27.8493
  135       0.0008       0.0460       0.0084       0.0026 28.1314
  136       0.0006       0.0461       0.0082       0.0026 26.9540
  137       0.0005       0.0475       0.0081       0.0027 27.9632
  138       0.0005       0.0474       0.0079       0.0027 27.8633
  139       0.0005       0.0475       0.0079       0.0027 26.8448
  140       0.0005       0.0483       0.0078       0.0028 27.9646
  141       0.0004       0.0477       0.0077       0.0027 26.9092
  142       0.0005       0.0466       0.0076       0.0026 26.7942
  143       0.0005       0.0466       0.0075       0.0026 26.7272
  144       0.0005       0.0451       0.0075       0.0025 27.8847
  145       0.0005       0.0437       0.0074       0.0023 27.8946
  146       0.0006       0.0444       0.0073       0.0024 26.8172
  147       0.0005       0.0435       0.0072       0.0023 26.8006
  148       0.0005       0.0437       0.0072       0.0023 26.9414
  149       0.0005       0.0431       0.0071       0.0022 26.8913
  150       0.0005       0.0411       0.0070       0.0020 28.0812
  151       0.0005       0.0402       0.0070       0.0019 27.8425
  152       0.0005       0.0403       0.0069       0.0020 27.9102
  153       0.0005       0.0402       0.0068       0.0019 27.9949
  154       0.0005       0.0405       0.0068       0.0020 26.9598
  155       0.0004       0.0390       0.0067       0.0018 27.8140
  156       0.0004       0.0392       0.0067       0.0018 26.8111
  157       0.0004       0.0393       0.0066       0.0019 26.9555
  158       0.0004       0.0392       0.0066       0.0018 26.8764
  159       0.0005       0.0390       0.0065       0.0018 27.9301
  160       0.0004       0.0401       0.0065       0.0019 26.7982
  161       0.0004       0.0392       0.0065       0.0019 26.8739
  162       0.0004       0.0387       0.0064       0.0018 27.8912
  163       0.0004       0.0387       0.0063       0.0018 27.1816
  164       0.0003       0.0391       0.0063       0.0018 26.6234
  165       0.0004       0.0389       0.0062       0.0018 27.8729
  166       0.0004       0.0378       0.0062       0.0017 27.1041
  167       0.0004       0.0374       0.0062       0.0017 27.9197
  168       0.0004       0.0363       0.0061       0.0016 26.7416
  169       0.0004       0.0358       0.0061       0.0015 26.6808
  170       0.0005       0.0358       0.0060       0.0015 26.7442
  171       0.0005       0.0341       0.0060       0.0014 27.8668
  172       0.0004       0.0343       0.0059       0.0014 26.9787
  173       0.0004       0.0341       0.0059       0.0014 26.7742
  174       0.0005       0.0340       0.0058       0.0014 26.6599
  175       0.0004       0.0331       0.0058       0.0013 26.0798
  176       0.0005       0.0332       0.0058       0.0013 27.0430
  177       0.0004       0.0335       0.0057       0.0014 27.0781
  178       0.0005       0.0339       0.0057       0.0014 27.0814
  179       0.0004       0.0333       0.0056       0.0013 26.1243
  180       0.0004       0.0333       0.0056       0.0013 26.7985
  181       0.0004       0.0333       0.0056       0.0013 25.7745
  182       0.0005       0.0327       0.0055       0.0013 25.7542
  183       0.0005       0.0329       0.0055       0.0013 26.7757
  184       0.0004       0.0326       0.0055       0.0013 26.7855
  185       0.0005       0.0331       0.0054       0.0013 26.7819
  186       0.0004       0.0333       0.0054       0.0013 25.7057
  187       0.0005       0.0327       0.0053       0.0013 26.1045
  188       0.0005       0.0326       0.0053       0.0013 25.7673
  189       0.0005       0.0322       0.0053       0.0013 26.8203
  190       0.0005       0.0319       0.0052       0.0012 25.7371
  191       0.0004       0.0316       0.0052       0.0012 26.7381
  192       0.0004       0.0313       0.0052       0.0012 26.7989
  193       0.0004       0.0315       0.0051       0.0012 25.7095
  194       0.0005       0.0311       0.0051       0.0012 25.8077
  195       0.0004       0.0314       0.0051       0.0012 26.7750
  196       0.0004       0.0312       0.0051       0.0012 25.9690
  197       0.0004       0.0312       0.0050       0.0012 26.0538
  198       0.0004       0.0309       0.0050       0.0012 26.0196
  199       0.0004       0.0312       0.0050       0.0012 25.8909
  200       0.0005       0.0309       0.0050       0.0012 27.0063
...Training Complete!

