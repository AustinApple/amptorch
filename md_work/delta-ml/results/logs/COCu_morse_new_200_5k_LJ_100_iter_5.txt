Fri Mar 13 16:06:26 2020
--------------------------------------------------
LJ-Parameter Optimization
inital LJ parameter guess [sig, eps]: {'C': [0.972, 6.379, 0.477], 'O': [1.09, 8.575, 0.603], 'Cu': [2.168, 3.8386, 1.696]}
Optimizer results: 
 fun: 118.03195536977726 
 message: Max. number of function evaluations reached 
 nfev: 100 
 nit: 23 
 success: False
Fitted LJ parameters: {'C': array([1.43427568, 6.33889503, 1.04296759]), 'O': array([1.31796914, 8.55892453, 1.        ]), 'Cu': array([2.20656393, 3.78066084, 1.13683221])} 

Optimization time: 3132.0437903404236 

Filename: COCu_morse_new_200_5k_LJ_100_iter_5
Dataset size: 700
Target scaling: [8.841315589518457, -1138.2796419305348]
Symmetry function parameters:
     G2_etas: [0.05       0.09653489 0.18637969 0.35984284 0.69474775 1.3413479
 2.58973734 5.        ]
     G2_rs_s: [0, 0, 0, 0, 0, 0, 0, 0]
     G4_etas: [0.005, 0.01]
     G4_zetas: [1.0, 4.0, 6.0]
     G4_gammas: [1.0, -1]
     cutoff: 5.876798323827276
Device: cpu
Model: FullNN(
  (elementwise_models): ModuleDict(
    (Cu): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=96, out_features=30, bias=True)
        (1): Tanh()
        (2): Linear(in_features=30, out_features=30, bias=True)
        (3): Tanh()
        (4): Linear(in_features=30, out_features=30, bias=True)
        (5): Tanh()
        (6): Linear(in_features=30, out_features=1, bias=True)
      )
    )
    (O): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=96, out_features=30, bias=True)
        (1): Tanh()
        (2): Linear(in_features=30, out_features=30, bias=True)
        (3): Tanh()
        (4): Linear(in_features=30, out_features=30, bias=True)
        (5): Tanh()
        (6): Linear(in_features=30, out_features=1, bias=True)
      )
    )
    (C): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=96, out_features=30, bias=True)
        (1): Tanh()
        (2): Linear(in_features=30, out_features=30, bias=True)
        (3): Tanh()
        (4): Linear(in_features=30, out_features=30, bias=True)
        (5): Tanh()
        (6): Linear(in_features=30, out_features=1, bias=True)
      )
    )
  )
)
Architecture:
   Input Layer - 96
   # of Hidden Layers - 3
   Nodes/Layer - 30
Loss Function: <class 'amptorch.model.CustomLoss'>
Force coefficient: 0.04
Optimizer: <class 'torch.optim.lbfgs.LBFGS'>
Learning Rate: 0.1
Batch Size: 700
Epochs: 200
Shuffle: False
Train Split (k-fold if int, fraction if float): 5

Training initiated...
Epoch   EnergyRMSE    ForceRMSE    TrainLoss    ValidLoss     Dur
===== ============ ============ ============ ============ =======
    1       1.7837       8.9893   11527.2910     448.9847 68.3631
    2       0.2748       6.0989    2369.6787     109.4371 68.9250
    3       0.4636       6.0920    1345.7738     118.9590 72.1473
    4       0.4664       5.7547    1151.0360     107.9513 71.4697
    5       0.3031       5.2705    1096.6156      84.2105 82.8263
    6       0.3737       5.3279    1055.4100      89.2613 82.6939
    7       0.3529       5.0416    1033.2554      79.8890 80.8672
    8       0.3625       4.6269    1015.9972      69.1398 82.9062
    9       0.3558       4.5443     994.7026      66.6837 79.4244
   10       0.3702       4.5083     985.6198      66.5040 79.9922
   11       0.4611       4.5698     976.8569      73.3543 80.4646
   12       0.4746       4.5180     966.5042      72.9221 82.1326
   13       0.4118       4.2181     955.4056      61.6874 80.5084
   14       0.3714       4.0670     945.0939      55.9693 80.7192
   15       0.2797       4.0395     931.4811      51.1650 81.9909
   16       0.2412       4.0330     920.8083      49.6140 100.1309
   17       0.2263       3.8899     915.7556      45.9538 79.5679
   18       0.2246       3.9258     910.4112      46.6851 82.2634
   19       0.1940       3.4061     900.2181      35.1196 78.5870
   20       0.1780       3.5699     894.5435      37.9025 79.0171
   21       0.1939       3.7456     883.7167      41.9151 81.6702
   22       0.2100       3.6320     879.9162      40.0233 99.3823
   23       0.1868       3.0811     876.5092      29.0230 94.0647
   24       0.2154       2.7899     870.1484      25.0436 88.5768
   25       0.1911       2.9457     851.7675      26.8529 90.7478
   26       0.1831       2.8725     836.3051      25.4512 90.4037
   27       0.2176       3.1431     820.8948      30.9760 88.3972
   28       0.2008       3.1100     791.9874      29.9042 88.4545
   29       0.1810       3.1894     760.8852      30.7762 91.4863
   30       0.2044       3.0587     739.2443      29.1196 93.5751
   31       0.1713       2.9420     713.1147      26.2895 90.2940
   32       0.1771       2.8688     700.4124      25.2397 89.9438
   33       0.1590       2.7319     687.4855      22.6670 90.1702
   34       0.1759       2.7924     677.7260      23.9978 94.8098
   35       0.1571       2.7758     667.6793      23.3013 91.4827
   36       0.1610       2.8545     658.6424      24.6281 87.1006
   37       0.1767       2.9030     644.7604      25.7821 90.9958
   38       0.1798       3.0081     627.4701      27.6006 92.3763
   39       0.1858       3.0166     607.0538      27.8952 89.9468
   40       0.1758       3.0398     592.4708      28.0349 90.4032
   41       0.1873       2.8353     573.4194      24.9654 77.7908
   42       0.1772       3.0190     554.6513      27.7168 74.1935
   43       0.1552       3.0534     526.1276      27.7915 74.9621
   44       0.1406       2.9194     490.1032      25.2468 92.0482
   45       0.1400       3.0047     456.6415      26.6513 78.1267
   46       0.1577       2.9920     424.7914      26.8051 71.3102
   47       0.1649       3.1767     404.8457      30.1604 79.6409
   48       0.1474       3.1891     384.1626      29.9973 80.8403
   49       0.1410       3.3283     366.8860      32.4101 81.8273
   50       0.1487       3.2894     348.4317      31.8436 79.8236
   51       0.1614       3.3332     341.6843      32.9328 81.8260
   52       0.1754       3.3345     331.6449      33.2851 81.7893
   53       0.1544       3.0630     323.8623      27.9382 82.8600
   54       0.1349       2.9784     317.0542      26.1126 82.2637
   55       0.1269       2.9316     309.1401      25.1911 82.0422
   56       0.1285       3.0086     301.6541      26.4992 82.3160
   57       0.1231       2.9718     298.0110      25.7890 81.8299
   58       0.1253       2.9403     295.0967      25.3059 80.4319
   59       0.1254       2.9637     291.2853      25.6938 72.2067
   60       0.1168       2.8340     288.0236      23.4425 75.1795
   61       0.1096       2.8673     284.3771      23.8607 72.2038
   62       0.1094       2.8655     281.6402      23.8279 72.4972
   63       0.1124       2.9058     279.5408      24.5259 72.3568
   64       0.1129       2.9194     276.4375      24.7564 72.8590
   65       0.1149       2.8421     274.8154      23.5405 71.9273
   66       0.1134       2.8362     272.9250      23.4229 75.9651
   67       0.1345       2.9771     269.9481      26.0818 74.4700
   68       0.1293       2.9036     266.0434      24.7772 73.0281
   69       0.1270       2.8539     263.6856      23.9354 72.2742
   70       0.1160       2.9871     262.0725      25.9250 72.4630
   71       0.1211       2.9306     259.6450      25.0744 71.5614
   72       0.1312       2.6798     257.7802      21.3133 72.5783
   73       0.1343       2.6361     254.9235      20.7198 105.7751
   74       0.1600       2.6801     252.6182      21.9036 81.5865
   75       0.1520       2.6590     250.9646      21.4152 83.1640
   76       0.1621       2.6594     250.0838      21.6434 86.1972
   77       0.1716       2.6742     248.6137      22.0848 86.4207
   78       0.1791       2.7006     246.4242      22.6670 87.9568
   79       0.1682       2.6254     245.2625      21.2809 86.7858
   80       0.1706       2.6031     243.8105      21.0112 89.3626
   81       0.1680       2.6469     242.6842      21.5934 90.3600
   82       0.1723       2.6971     241.2332      22.4459 85.8894
   83       0.1849       2.9543     238.9290      26.8326 86.8562
   84       0.1752       2.9153     235.9888      25.9449 86.8998
   85       0.1726       2.8544     233.9235      24.8992 90.1554
   86       0.1554       2.7088     231.1314      22.2363 89.9486
   87       0.1615       2.7499     228.8743      22.9993 81.2705
   88       0.1674       2.8221     227.1028      24.2620 87.1080
   89       0.1639       2.8846     226.1599      25.1789 86.5183
   90       0.1536       2.6724     225.5187      21.6487 89.4354
   91       0.1471       2.6807     224.3927      21.6353 86.4015
   92       0.1412       2.7169     223.0792      22.0637 87.1594
   93       0.1342       2.8333     221.3710      23.7389 91.1239
   94       0.1299       2.7071     219.6440      21.7005 90.3899
   95       0.1338       2.8967     218.5515      24.7480 87.3575
   96       0.1338       3.1900     217.3182      29.7456 87.3904
   97       0.1309       2.9414     216.3330      25.4257 85.9556
   98       0.1468       3.4298     215.4852      34.4459 86.2560
   99       0.1415       3.5632     214.0445      36.9529 86.5938
  100       0.1469       3.6072     212.8065      37.9441 88.2456
  101       0.1329       3.7786     211.9365      41.2134 89.7499
  102       0.1326       3.8173     210.9366      42.0310 89.4245
  103       0.1312       3.7624     210.0665      40.8416 91.2921
  104       0.1272       3.0473     208.5213      27.1327 90.2363
  105       0.1332       2.8811     207.3317      24.4829 87.4666
  106       0.1304       2.6166     206.6738      20.3612 87.6367
  107       0.1291       2.6537     205.6841      20.8852 90.4722
  108       0.1234       2.1922     204.8527      14.5229 86.9417
  109       0.1175       2.0095     203.8533      12.2726 88.1095
  110       0.1251       1.9615     202.8900      11.8694 87.2505
  111       0.1256       1.7977     202.0112      10.1525 87.9940
  112       0.1257       1.6638     201.5124       8.8574 90.1083
  113       0.1270       1.6341     201.0374       8.6062 87.3987
  114       0.1233       1.7007     200.5811       9.1622 90.3296
  115       0.1287       1.5798     199.6823       8.1477 90.1966
  116       0.1276       1.5883     198.8331       8.2038 91.3391
  117       0.1236       1.5240     198.2177       7.5735 87.0722
  118       0.1256       1.4811     197.5790       7.2460 87.8358
  119       0.1295       1.4224     196.8629       6.8393 87.3481
  120       0.1240       1.3797     196.2882       6.4058 90.7844
  121       0.1299       1.3290     195.4348       6.1262 87.8509
  122       0.1364       1.3111     194.4261       6.1154 87.0305
  123       0.1424       1.3208     193.7935       6.3042 86.1159
  124       0.1474       1.4405     192.9607       7.3315 90.3885
  125       0.1390       1.3693     192.0003       6.6015 86.8575
  126       0.1349       1.3524     191.1174       6.3959 87.5020
  127       0.1376       1.4566     190.5263       7.2657 86.1104
  128       0.1222       1.3034     189.5009       5.8018 91.1132
  129       0.1156       1.2890     188.1621       5.5866 87.4905
  130       0.1129       1.3810     187.1419       6.2322 89.5664
  131       0.1124       1.4719     186.3623       6.9509 90.1465
  132       0.1123       1.4022     185.0751       6.3877 87.4030
  133       0.1148       1.4020     184.3830       6.4260 90.6398
  134       0.1156       1.2837     183.3747       5.5489 87.3369
  135       0.1162       1.3467     182.9041       6.0231 87.1358
  136       0.1164       1.3113     181.8235       5.7633 87.1908
  137       0.1191       1.3160     181.1526       5.8428 90.3414
  138       0.1283       1.3765     180.8339       6.4584 87.5813
  139       0.1216       1.3211     180.2905       5.9217 90.0913
  140       0.1223       1.3442     179.6035       6.1061 86.8974
  141       0.1169       1.2762     179.1352       5.5171 91.3257
  142       0.1209       1.2503     178.2587       5.4010 90.0045
  143       0.1260       1.2424     177.5730       5.4329 90.6679
  144       0.1293       1.2292     176.8187       5.4016 91.3568
  145       0.1269       1.2884     176.0002       5.7748 86.3162
  146       0.1282       1.2979     175.4014       5.8679 80.8571
  147       0.1279       1.2858     174.9406       5.7736 83.5207
  148       0.1274       1.2217     174.3022       5.3159 80.0457
  149       0.1228       1.1996     173.6771       5.0857 83.4293
  150       0.1271       1.1476     173.1916       4.8189 83.6616
  151       0.1294       1.1385     172.2713       4.8010 82.8960
  152       0.1313       1.0726     171.7305       4.4270 79.2257
  153       0.1343       1.0848     171.4560       4.5580 79.0281
  154       0.1350       1.0578     170.9348       4.4089 81.6118
  155       0.1328       1.0731     170.6658       4.4586 79.0642
  156       0.1393       1.0625     170.3038       4.5186 81.9619
  157       0.1332       1.0488     169.5193       4.3226 82.0373
  158       0.1329       1.0824     169.1302       4.5176 81.7155
  159       0.1379       1.1226     168.6278       4.8595 79.2693
  160       0.1408       1.1137     167.9042       4.8609 82.4139
  161       0.1511       1.1657     167.2689       5.4028 79.4827
  162       0.1465       1.1342     166.5260       5.1049 82.0291
  163       0.1469       1.1174     165.5627       5.0062 81.9809
  164       0.1488       1.0842     164.9676       4.8417 79.6042
  165       0.1436       1.0448     163.9271       4.5003 82.0673
  166       0.1405       1.0384     163.3416       4.4004 82.2152
  167       0.1429       1.0212     162.9763       4.3487 78.8334
  168       0.1417       1.0379     162.5461       4.4217 79.4767
  169       0.1403       1.0330     161.7696       4.3655 79.3147
  170       0.1446       1.0331     161.2860       4.4514 82.0851
  171       0.1409       1.0361     160.9030       4.3956 78.9230
  172       0.1424       0.9981     160.5776       4.2086 78.7448
  173       0.1373       0.9701     160.1293       3.9552 82.8127
  174       0.1353       0.9647     159.6045       3.8871 81.9237
  175       0.1272       0.9491     158.9250       3.6553 79.1107
  176       0.1285       0.9509     158.2739       3.6884 73.6369
  177       0.1234       0.9553     157.7130       3.6214 73.4343
  178       0.1232       0.9716     156.9897       3.7061 73.3296
  179       0.1207       0.9677     156.6504       3.6427 72.8340
  180       0.1226       0.9616     156.3049       3.6417 71.5159
  181       0.1252       0.9586     155.9211       3.6702 70.5775
  182       0.1186       0.9645     155.6203       3.5901 67.2101
  183       0.1188       0.9603     155.2400       3.5709 69.0685
  184       0.1208       0.9586     154.7878       3.5935 68.5690
  185       0.1143       0.9656     154.3370       3.5248 69.0308
  186       0.1132       0.9577     153.7036       3.4654 69.3231
  187       0.1125       0.9523     153.3848       3.4248 69.1006
  188       0.1082       0.9848     152.8790       3.5349 68.6889
  189       0.1080       0.9878     152.4184       3.5483 69.0528
  190       0.1004       1.0716     151.7886       3.9208 69.8538
  191       0.1026       1.0038     151.2143       3.5584 68.7078
  192       0.1031       0.9628     150.8464       3.3401 68.8582
  193       0.1020       0.9183     150.3647       3.0894 66.2352
  194       0.1059       0.9095     149.8839       3.1009 66.4348
  195       0.1102       0.9237     149.4346       3.2397 77.0016
  196       0.1107       0.9298     149.2846       3.2777 72.9438
  197       0.1067       0.9249     148.9146       3.1919 70.1902
  198       0.1031       0.9180     148.6810       3.1028 71.6161
  199       0.0966       0.9280     148.3469       3.0642 71.2473
  200       0.0981       0.9449     147.8079       3.1729 71.9440
...Training Complete!

