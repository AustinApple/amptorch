Fri Mar 13 03:24:49 2020
--------------------------------------------------
LJ-Parameter Optimization
inital LJ parameter guess [sig, eps]: {'C': [0.972, 6.379], 'O': [1.09, 8.575], 'Cu': [2.168, 3.8386]}
Optimizer results: 
 fun: 0.5606357399408874 
 message: Local minimum reached (|pg| ~= 0) 
 nfev: 24 
 nit: 7 
 success: True
Fitted LJ parameters: {'C': array([1.e+00, 1.e-05]), 'O': array([1.e+00, 1.e-05]), 'Cu': array([1.e+00, 1.e-05])} 

a: 15.0
Optimization time: 291.6086673736572 

Filename: COCu_rep_new_200_5k_LJ_100_iter_2
Dataset size: 400
Target scaling: [8.841315589518457, 6.990871105586963e-07]
Symmetry function parameters:
     G2_etas: [0.05       0.09653489 0.18637969 0.35984284 0.69474775 1.3413479
 2.58973734 5.        ]
     G2_rs_s: [0, 0, 0, 0, 0, 0, 0, 0]
     G4_etas: [0.005, 0.01]
     G4_zetas: [1.0, 4.0, 6.0]
     G4_gammas: [1.0, -1]
     cutoff: 5.876798323827276
Device: cpu
Model: FullNN(
  (elementwise_models): ModuleDict(
    (Cu): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=96, out_features=30, bias=True)
        (1): Tanh()
        (2): Linear(in_features=30, out_features=30, bias=True)
        (3): Tanh()
        (4): Linear(in_features=30, out_features=30, bias=True)
        (5): Tanh()
        (6): Linear(in_features=30, out_features=1, bias=True)
      )
    )
    (O): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=96, out_features=30, bias=True)
        (1): Tanh()
        (2): Linear(in_features=30, out_features=30, bias=True)
        (3): Tanh()
        (4): Linear(in_features=30, out_features=30, bias=True)
        (5): Tanh()
        (6): Linear(in_features=30, out_features=1, bias=True)
      )
    )
    (C): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=96, out_features=30, bias=True)
        (1): Tanh()
        (2): Linear(in_features=30, out_features=30, bias=True)
        (3): Tanh()
        (4): Linear(in_features=30, out_features=30, bias=True)
        (5): Tanh()
        (6): Linear(in_features=30, out_features=1, bias=True)
      )
    )
  )
)
Architecture:
   Input Layer - 96
   # of Hidden Layers - 3
   Nodes/Layer - 30
Loss Function: <class 'amptorch.model.CustomLoss'>
Force coefficient: 0.04
Optimizer: <class 'torch.optim.lbfgs.LBFGS'>
Learning Rate: 0.1
Batch Size: 400
Epochs: 200
Shuffle: False
Train Split (k-fold if int, fraction if float): 5

Training initiated...
Epoch   EnergyRMSE    ForceRMSE    TrainLoss    ValidLoss     Dur
===== ============ ============ ============ ============ =======
    1       0.0238       0.3169      10.6591       0.1834 41.1594
    2       0.0097       0.3188       4.4469       0.1664 42.6586
    3       0.0184       0.3297       3.7476       0.1875 42.9094
    4       0.0283       0.3250       3.0585       0.2011 42.8097
    5       0.0059       0.3180       2.7719       0.1632 41.1567
    6       0.0041       0.3212       2.4399       0.1657 41.1515
    7       0.0139       0.3195       2.0479       0.1711 41.1535
    8       0.0117       0.3117       1.8502       0.1610 41.0868
    9       0.0161       0.3097       1.5319       0.1638 40.9882
   10       0.0064       0.3117       1.1935       0.1571 41.5236
   11       0.0102       0.3166       1.0422       0.1645 41.4159
   12       0.0054       0.3135       0.8855       0.1584 41.3987
   13       0.0067       0.3160       0.7809       0.1615 41.4646
   14       0.0046       0.3132       0.6744       0.1578 41.4938
   15       0.0103       0.3127       0.6004       0.1607 41.0695
   16       0.0120       0.3110       0.5486       0.1605 41.1310
   17       0.0121       0.3093       0.5047       0.1589 40.9677
   18       0.0100       0.3074       0.4739       0.1552 43.0695
   19       0.0058       0.2946       0.4395       0.1402 43.1817
   20       0.0093       0.2924       0.3917       0.1402 43.0379
   21       0.0101       0.2865       0.3562       0.1354 41.4073
   22       0.0091       0.2805       0.3255       0.1292 42.6058
   23       0.0057       0.2796       0.2925       0.1263 41.3924
   24       0.0037       0.2810       0.2788       0.1269 41.4754
   25       0.0044       0.2771       0.2675       0.1236 41.4817
   26       0.0047       0.2746       0.2552       0.1216 43.1095
   27       0.0047       0.2740       0.2457       0.1210 41.2065
   28       0.0051       0.2744       0.2360       0.1215 41.1480
   29       0.0051       0.2735       0.2316       0.1207 41.4523
   30       0.0034       0.2731       0.2267       0.1198 43.1012
   31       0.0045       0.2718       0.2227       0.1190 43.0123
   32       0.0040       0.2716       0.2168       0.1187 41.4025
   33       0.0084       0.2714       0.2133       0.1207 41.4934
   34       0.0088       0.2705       0.2085       0.1201 40.9998
   35       0.0098       0.2703       0.2048       0.1208 41.4946
   36       0.0093       0.2700       0.2002       0.1201 43.2016
   37       0.0058       0.2687       0.1970       0.1169 43.1687
   38       0.0043       0.2676       0.1929       0.1153 41.2205
   39       0.0051       0.2674       0.1912       0.1154 41.4545
   40       0.0057       0.2663       0.1882       0.1148 42.7966
   41       0.0064       0.2659       0.1847       0.1148 43.0962
   42       0.0068       0.2641       0.1824       0.1135 43.0692
   43       0.0047       0.2625       0.1792       0.1112 42.9850
   44       0.0041       0.2605       0.1750       0.1093 43.1193
   45       0.0039       0.2574       0.1718       0.1066 43.0628
   46       0.0061       0.2575       0.1676       0.1076 53.1152
   47       0.0058       0.2553       0.1655       0.1056 42.3677
   48       0.0064       0.2533       0.1629       0.1043 44.8424
   49       0.0065       0.2500       0.1600       0.1017 43.8574
   50       0.0058       0.2488       0.1573       0.1004 43.7733
   51       0.0064       0.2458       0.1551       0.0983 45.5679
   52       0.0049       0.2431       0.1526       0.0955 44.0253
   53       0.0055       0.2414       0.1487       0.0945 43.9411
   54       0.0064       0.2386       0.1467       0.0927 43.8360
   55       0.0070       0.2368       0.1445       0.0917 43.7749
   56       0.0043       0.2336       0.1424       0.0881 43.6738
   57       0.0042       0.2312       0.1393       0.0863 45.4310
   58       0.0057       0.2244       0.1376       0.0819 43.7978
   59       0.0039       0.2222       0.1325       0.0796 43.7612
   60       0.0059       0.2194       0.1304       0.0784 44.1829
   61       0.0036       0.2180       0.1271       0.0766 45.5168
   62       0.0036       0.2164       0.1249       0.0754 45.3128
   63       0.0031       0.2143       0.1226       0.0738 43.5031
   64       0.0030       0.2129       0.1211       0.0729 43.5598
   65       0.0027       0.2104       0.1190       0.0711 43.5450
   66       0.0029       0.2107       0.1175       0.0714 45.1674
   67       0.0034       0.2108       0.1153       0.0716 44.9835
   68       0.0029       0.2080       0.1140       0.0696 45.6470
   69       0.0030       0.2078       0.1121       0.0694 43.8084
   70       0.0028       0.2078       0.1107       0.0694 43.6462
   71       0.0028       0.2057       0.1092       0.0680 43.4367
   72       0.0025       0.2049       0.1072       0.0674 45.4071
   73       0.0030       0.2047       0.1052       0.0674 43.6684
   74       0.0030       0.2054       0.1040       0.0679 45.4795
   75       0.0030       0.2066       0.1024       0.0686 45.4199
   76       0.0027       0.2060       0.1015       0.0682 44.0637
   77       0.0027       0.2064       0.1002       0.0684 44.8684
   78       0.0027       0.2073       0.0994       0.0690 43.9088
   79       0.0028       0.2080       0.0982       0.0695 43.5718
   80       0.0026       0.2076       0.0965       0.0692 43.4114
   81       0.0037       0.2055       0.0951       0.0682 43.4418
   82       0.0027       0.2056       0.0925       0.0679 45.5512
   83       0.0032       0.2061       0.0907       0.0684 45.5456
   84       0.0038       0.2080       0.0895       0.0698 45.3593
   85       0.0038       0.2094       0.0884       0.0708 45.2542
   86       0.0031       0.2105       0.0875       0.0713 43.8036
   87       0.0030       0.2077       0.0858       0.0694 45.6174
   88       0.0026       0.2059       0.0846       0.0681 43.7375
   89       0.0029       0.2063       0.0833       0.0685 43.5421
   90       0.0027       0.2040       0.0820       0.0669 43.5277
   91       0.0027       0.2025       0.0809       0.0659 45.2217
   92       0.0027       0.1996       0.0800       0.0640 45.6012
   93       0.0025       0.2007       0.0788       0.0647 43.5906
   94       0.0025       0.2001       0.0783       0.0643 45.6567
   95       0.0025       0.1988       0.0774       0.0635 45.2009
   96       0.0025       0.1996       0.0767       0.0640 43.3736
   97       0.0029       0.2020       0.0759       0.0656 43.9364
   98       0.0027       0.2027       0.0751       0.0661 43.5590
   99       0.0031       0.2029       0.0744       0.0662 45.2304
  100       0.0029       0.2041       0.0733       0.0670 44.0879
  101       0.0033       0.2028       0.0725       0.0662 43.5516
  102       0.0029       0.2027       0.0719       0.0661 45.0588
  103       0.0028       0.2003       0.0714       0.0645 45.7444
  104       0.0026       0.1998       0.0708       0.0641 45.7231
  105       0.0025       0.2012       0.0701       0.0650 45.6296
  106       0.0025       0.2026       0.0696       0.0659 45.5637
  107       0.0026       0.2058       0.0687       0.0681 45.4900
  108       0.0026       0.2070       0.0673       0.0689 45.6421
  109       0.0027       0.2093       0.0669       0.0704 45.4044
  110       0.0027       0.2102       0.0664       0.0710 45.2236
  111       0.0033       0.2071       0.0655       0.0691 43.4315
  112       0.0032       0.2060       0.0645       0.0683 43.6216
  113       0.0034       0.2076       0.0637       0.0694 43.7812
  114       0.0030       0.2099       0.0630       0.0709 45.5341
  115       0.0026       0.2064       0.0624       0.0684 43.6653
  116       0.0026       0.2057       0.0620       0.0680 45.3393
  117       0.0027       0.2038       0.0615       0.0668 45.5179
  118       0.0027       0.2051       0.0610       0.0676 43.7044
  119       0.0028       0.2056       0.0607       0.0680 43.7596
  120       0.0030       0.2067       0.0600       0.0687 43.4006
  121       0.0029       0.2090       0.0595       0.0702 45.4522
  122       0.0034       0.2090       0.0591       0.0704 43.9791
  123       0.0035       0.2090       0.0586       0.0704 45.4412
  124       0.0029       0.2103       0.0580       0.0711 43.2948
  125       0.0027       0.2080       0.0575       0.0695 43.7869
  126       0.0030       0.2078       0.0569       0.0694 43.4369
  127       0.0028       0.2082       0.0566       0.0697 44.1246
  128       0.0028       0.2069       0.0560       0.0688 43.9960
  129       0.0028       0.2059       0.0558       0.0681 43.7578
  130       0.0030       0.2039       0.0554       0.0669 43.8828
  131       0.0032       0.2021       0.0551       0.0657 45.9319
  132       0.0030       0.2012       0.0546       0.0651 45.2759
  133       0.0029       0.2004       0.0542       0.0646 43.7545
  134       0.0031       0.1973       0.0538       0.0627 43.2535
  135       0.0033       0.1966       0.0535       0.0623 44.0203
  136       0.0033       0.1966       0.0532       0.0622 43.4774
  137       0.0032       0.1988       0.0528       0.0636 43.8358
  138       0.0034       0.1986       0.0525       0.0636 43.8762
  139       0.0034       0.1994       0.0524       0.0641 44.1424
  140       0.0032       0.1981       0.0521       0.0632 45.6289
  141       0.0033       0.1969       0.0518       0.0625 43.5103
  142       0.0033       0.1973       0.0515       0.0627 45.5780
  143       0.0034       0.1970       0.0512       0.0625 45.6509
  144       0.0034       0.1949       0.0510       0.0613 44.1543
  145       0.0036       0.1948       0.0508       0.0612 43.8334
  146       0.0038       0.1970       0.0506       0.0627 45.6584
  147       0.0046       0.1989       0.0502       0.0641 45.7436
  148       0.0052       0.1970       0.0499       0.0632 45.6166
  149       0.0050       0.1971       0.0497       0.0631 45.7855
  150       0.0054       0.1973       0.0494       0.0635 43.9643
  151       0.0055       0.1958       0.0491       0.0626 45.0668
  152       0.0057       0.1983       0.0487       0.0642 45.5607
  153       0.0065       0.2005       0.0482       0.0660 43.3819
  154       0.0065       0.2008       0.0479       0.0662 44.0164
  155       0.0067       0.2008       0.0476       0.0664 45.5606
  156       0.0068       0.2040       0.0473       0.0684 45.3893
  157       0.0064       0.2053       0.0471       0.0691 45.5628
  158       0.0069       0.2067       0.0470       0.0703 43.6425
  159       0.0067       0.2066       0.0467       0.0701 45.4337
  160       0.0061       0.2074       0.0465       0.0703 43.2681
  161       0.0066       0.2102       0.0462       0.0724 43.6587
  162       0.0071       0.2108       0.0459       0.0731 45.3609
  163       0.0069       0.2125       0.0457       0.0742 43.9914
  164       0.0067       0.2120       0.0455       0.0737 43.7454
  165       0.0063       0.2126       0.0452       0.0739 45.4070
  166       0.0062       0.2144       0.0449       0.0751 45.5743
  167       0.0065       0.2146       0.0448       0.0754 45.6285
  168       0.0067       0.2135       0.0446       0.0747 45.5880
  169       0.0059       0.2127       0.0445       0.0738 45.4306
  170       0.0063       0.2152       0.0442       0.0757 43.8607
  171       0.0065       0.2165       0.0439       0.0767 45.2688
  172       0.0064       0.2165       0.0437       0.0766 45.4772
  173       0.0062       0.2166       0.0434       0.0766 43.7897
  174       0.0064       0.2199       0.0433       0.0790 45.0222
  175       0.0061       0.2225       0.0430       0.0807 44.9979
  176       0.0059       0.2228       0.0428       0.0808 43.9562
  177       0.0055       0.2255       0.0427       0.0826 45.3323
  178       0.0056       0.2265       0.0425       0.0833 43.3335
  179       0.0055       0.2282       0.0424       0.0845 43.8543
  180       0.0055       0.2283       0.0422       0.0846 45.2847
  181       0.0059       0.2299       0.0419       0.0860 45.0088
  182       0.0064       0.2334       0.0417       0.0888 45.4559
  183       0.0064       0.2342       0.0415       0.0894 45.3503
  184       0.0064       0.2349       0.0412       0.0899 45.2742
  185       0.0066       0.2357       0.0410       0.0906 45.6109
  186       0.0071       0.2392       0.0408       0.0935 45.6325
  187       0.0074       0.2397       0.0406       0.0941 45.6109
  188       0.0078       0.2411       0.0405       0.0954 43.7957
  189       0.0078       0.2410       0.0402       0.0953 43.9017
  190       0.0081       0.2438       0.0400       0.0977 43.6714
  191       0.0083       0.2446       0.0399       0.0985 45.5062
  192       0.0077       0.2495       0.0397       0.1020 45.2061
  193       0.0076       0.2492       0.0394       0.1017 45.1302
  194       0.0075       0.2505       0.0393       0.1026 43.5646
  195       0.0073       0.2521       0.0391       0.1038 43.4348
  196       0.0076       0.2527       0.0389       0.1045 43.5038
  197       0.0071       0.2536       0.0388       0.1049 43.7417
  198       0.0071       0.2530       0.0387       0.1044 43.7353
  199       0.0071       0.2529       0.0386       0.1044 45.3450
  200       0.0070       0.2554       0.0385       0.1063 45.5351
...Training Complete!

