Tue Mar 10 15:48:46 2020
--------------------------------------------------
LJ-Parameter Optimization
inital LJ parameter guess [sig, eps]: {'C': [1.0, 6.3535], 'O': [1.0808, 8.5357], 'Cu': [2.1717, 3.7575]}
Optimizer results: 
 fun: 0.30580734090489836 
 message: Maximum number of function evaluations has been exceeded. 
 nfev: 1400 
 nit: 929 
 success: False
Fitted LJ parameters: {'C': array([1.17833206e+00, 1.29230350e-04]), 'O': array([0.64636504, 0.00400537]), 'Cu': array([0.84092445, 7.47002997])} 

a: 6.015128584408309
Optimization time: 1445.263697385788 

Filename: COCu_rep_fit_f100_LJ_100_iter_2
Dataset size: 300
Target scaling: [8.841315589518457, 1.857081105177049]
Symmetry function parameters:
     G2_etas: [0.05       0.23207944 1.07721735 5.        ]
     G2_rs_s: [0, 0, 0, 0]
     G4_etas: [0.005, 0.01]
     G4_zetas: [1.0, 4.0]
     G4_gammas: [1.0, -1]
     cutoff: 5.876798323827276
Device: cpu
Model: FullNN(
  (elementwise_models): ModuleDict(
    (Cu): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=60, out_features=20, bias=True)
        (1): Tanh()
        (2): Linear(in_features=20, out_features=20, bias=True)
        (3): Tanh()
        (4): Linear(in_features=20, out_features=1, bias=True)
      )
    )
    (O): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=60, out_features=20, bias=True)
        (1): Tanh()
        (2): Linear(in_features=20, out_features=20, bias=True)
        (3): Tanh()
        (4): Linear(in_features=20, out_features=1, bias=True)
      )
    )
    (C): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=60, out_features=20, bias=True)
        (1): Tanh()
        (2): Linear(in_features=20, out_features=20, bias=True)
        (3): Tanh()
        (4): Linear(in_features=20, out_features=1, bias=True)
      )
    )
  )
)
Architecture:
   Input Layer - 60
   # of Hidden Layers - 2
   Nodes/Layer - 20
Loss Function: <class 'amptorch.model.CustomLoss'>
Force coefficient: 0.04
Optimizer: <class 'torch.optim.lbfgs.LBFGS'>
Learning Rate: 0.1
Batch Size: 300
Epochs: 200
Shuffle: False
Train Split (k-fold if int, fraction if float): 5

Training initiated...
Epoch   EnergyRMSE    ForceRMSE    TrainLoss    ValidLoss     Dur
===== ============ ============ ============ ============ =======
    1       0.0051       0.2557      12.0743       0.0793 19.1855
    2       0.0060       0.2516       1.3249       0.0770 18.5353
    3       0.0070       0.2484       0.7903       0.0755 19.1346
    4       0.0059       0.2562       0.6395       0.0798 18.3221
    5       0.0052       0.2620       0.5463       0.0832 18.2440
    6       0.0038       0.2629       0.5036       0.0834 18.4916
    7       0.0040       0.2396       0.4789       0.0693 18.4804
    8       0.0017       0.2358       0.4373       0.0668 18.5700
    9       0.0040       0.2189       0.4001       0.0580 18.4876
   10       0.0053       0.2198       0.3678       0.0588 18.4427
   11       0.0024       0.2119       0.3449       0.0541 18.4300
   12       0.0020       0.2090       0.3272       0.0525 19.2668
   13       0.0012       0.2074       0.3133       0.0517 18.4913
   14       0.0022       0.1989       0.3063       0.0476 27.8225
   15       0.0020       0.1948       0.2995       0.0457 18.5815
   16       0.0029       0.1959       0.2894       0.0463 19.4524
   17       0.0023       0.1910       0.2775       0.0439 18.6815
   18       0.0038       0.1847       0.2701       0.0414 20.2106
   19       0.0024       0.1644       0.2594       0.0326 20.3499
   20       0.0016       0.1578       0.2375       0.0300 19.2810
   21       0.0030       0.1452       0.2249       0.0256 19.3157
   22       0.0037       0.1295       0.2111       0.0205 19.4026
   23       0.0014       0.1124       0.1971       0.0152 19.3150
   24       0.0011       0.0953       0.1843       0.0109 25.1074
   25       0.0005       0.0975       0.1726       0.0114 22.7147
   26       0.0011       0.0932       0.1670       0.0105 20.2887
   27       0.0019       0.0882       0.1591       0.0094 21.7242
   28       0.0019       0.0833       0.1548       0.0084 20.7086
   29       0.0014       0.0705       0.1505       0.0060 20.8401
   30       0.0028       0.0646       0.1449       0.0052 20.9729
   31       0.0020       0.0591       0.1393       0.0043 21.4467
   32       0.0028       0.0564       0.1335       0.0040 21.3403
   33       0.0038       0.0574       0.1319       0.0044 21.3116
   34       0.0032       0.0588       0.1284       0.0045 21.3315
   35       0.0021       0.0566       0.1257       0.0040 22.2697
   36       0.0015       0.0545       0.1220       0.0036 21.5781
   37       0.0021       0.0551       0.1192       0.0038 21.1180
   38       0.0013       0.0511       0.1184       0.0032 21.0101
   39       0.0006       0.0514       0.1159       0.0032 21.5003
   40       0.0009       0.0512       0.1136       0.0032 22.1591
   41       0.0010       0.0461       0.1127       0.0026 20.9598
   42       0.0010       0.0462       0.1107       0.0026 21.7555
   43       0.0009       0.0454       0.1085       0.0025 22.1036
   44       0.0006       0.0453       0.1074       0.0025 21.1370
   45       0.0005       0.0453       0.1053       0.0025 21.4742
   46       0.0008       0.0449       0.1045       0.0024 21.2665
   47       0.0007       0.0446       0.1027       0.0024 21.5575
   48       0.0010       0.0431       0.1009       0.0023 22.2308
   49       0.0007       0.0440       0.0995       0.0023 21.0957
   50       0.0011       0.0399       0.0989       0.0020 22.6139
   51       0.0006       0.0391       0.0961       0.0018 21.1575
   52       0.0007       0.0422       0.0947       0.0022 21.6072
   53       0.0008       0.0424       0.0934       0.0022 21.3736
   54       0.0017       0.0400       0.0916       0.0020 21.1772
   55       0.0009       0.0427       0.0896       0.0022 21.3771
   56       0.0010       0.0394       0.0882       0.0019 23.6541
   57       0.0014       0.0405       0.0867       0.0020 24.8234
   58       0.0016       0.0392       0.0861       0.0019 25.0385
   59       0.0008       0.0386       0.0850       0.0018 25.1957
   60       0.0007       0.0385       0.0839       0.0018 23.8347
   61       0.0013       0.0374       0.0827       0.0017 25.2021
   62       0.0009       0.0346       0.0817       0.0015 23.6936
   63       0.0009       0.0359       0.0805       0.0016 24.6782
   64       0.0016       0.0356       0.0797       0.0016 24.4784
   65       0.0019       0.0340       0.0781       0.0015 25.3299
   66       0.0012       0.0353       0.0770       0.0015 24.7828
   67       0.0022       0.0353       0.0750       0.0016 26.4294
   68       0.0012       0.0356       0.0735       0.0016 25.4188
   69       0.0010       0.0409       0.0719       0.0020 25.8121
   70       0.0012       0.0379       0.0709       0.0018 24.8535
   71       0.0010       0.0377       0.0699       0.0017 25.0786
   72       0.0009       0.0371       0.0687       0.0017 24.3394
   73       0.0008       0.0356       0.0676       0.0015 25.3911
   74       0.0008       0.0361       0.0659       0.0016 24.8425
   75       0.0015       0.0355       0.0646       0.0016 24.2986
   76       0.0012       0.0331       0.0637       0.0014 24.7356
   77       0.0021       0.0343       0.0620       0.0016 25.0673
   78       0.0010       0.0352       0.0613       0.0015 25.8091
   79       0.0018       0.0350       0.0598       0.0016 23.7909
   80       0.0010       0.0320       0.0584       0.0013 22.6974
   81       0.0013       0.0315       0.0571       0.0012 23.8547
   82       0.0007       0.0329       0.0565       0.0013 23.1979
   83       0.0007       0.0327       0.0554       0.0013 21.9276
   84       0.0011       0.0307       0.0546       0.0012 22.8138
   85       0.0010       0.0306       0.0541       0.0012 23.1709
   86       0.0010       0.0315       0.0535       0.0012 23.0886
   87       0.0012       0.0335       0.0530       0.0014 23.8337
   88       0.0013       0.0344       0.0523       0.0015 23.7004
   89       0.0015       0.0359       0.0518       0.0016 21.8075
   90       0.0013       0.0385       0.0509       0.0018 22.9954
   91       0.0009       0.0379       0.0503       0.0017 23.9034
   92       0.0008       0.0350       0.0498       0.0015 22.2911
   93       0.0009       0.0360       0.0493       0.0016 22.4016
   94       0.0009       0.0359       0.0490       0.0016 23.0378
   95       0.0011       0.0336       0.0485       0.0014 22.5029
   96       0.0012       0.0338       0.0481       0.0014 24.6057
   97       0.0009       0.0341       0.0475       0.0014 23.0723
   98       0.0011       0.0346       0.0469       0.0015 24.0179
   99       0.0010       0.0350       0.0465       0.0015 24.8837
  100       0.0011       0.0360       0.0455       0.0016 23.8268
  101       0.0012       0.0336       0.0449       0.0014 24.7597
  102       0.0009       0.0338       0.0444       0.0014 24.4414
  103       0.0012       0.0326       0.0440       0.0013 24.1132
  104       0.0010       0.0314       0.0434       0.0012 24.9265
  105       0.0011       0.0320       0.0431       0.0013 25.6337
  106       0.0010       0.0317       0.0424       0.0012 25.0248
  107       0.0013       0.0313       0.0422       0.0012 23.9991
  108       0.0009       0.0305       0.0417       0.0011 24.1422
  109       0.0010       0.0302       0.0411       0.0011 24.1544
  110       0.0012       0.0295       0.0409       0.0011 24.2663
  111       0.0010       0.0274       0.0404       0.0009 23.9110
  112       0.0009       0.0274       0.0401       0.0009 24.1909
  113       0.0011       0.0281       0.0397       0.0010 23.8424
  114       0.0011       0.0284       0.0394       0.0010 24.1634
  115       0.0011       0.0283       0.0392       0.0010 23.6606
  116       0.0011       0.0282       0.0389       0.0010 24.5764
  117       0.0012       0.0275       0.0387       0.0009 23.9818
  118       0.0010       0.0262       0.0385       0.0009 23.9499
  119       0.0010       0.0264       0.0382       0.0009 22.1133
  120       0.0013       0.0259       0.0380       0.0008 23.9799
  121       0.0013       0.0265       0.0377       0.0009 22.2758
  122       0.0010       0.0262       0.0376       0.0009 21.4904
  123       0.0011       0.0279       0.0375       0.0010 20.9703
  124       0.0012       0.0279       0.0373       0.0010 21.1432
  125       0.0010       0.0282       0.0369       0.0010 21.5467
  126       0.0011       0.0277       0.0366       0.0010 21.6209
  127       0.0011       0.0276       0.0364       0.0010 21.7277
  128       0.0011       0.0275       0.0363       0.0009 22.6098
  129       0.0008       0.0283       0.0362       0.0010 22.3021
  130       0.0008       0.0282       0.0361       0.0010 21.7551
  131       0.0006       0.0283       0.0360       0.0010 22.4573
  132       0.0009       0.0276       0.0357       0.0009 22.3702
  133       0.0008       0.0278       0.0356       0.0009 22.6534
  134       0.0007       0.0269       0.0355       0.0009 24.0544
  135       0.0008       0.0271       0.0351       0.0009 22.4038
  136       0.0009       0.0283       0.0350       0.0010 22.2971
  137       0.0009       0.0277       0.0348       0.0009 23.1357
  138       0.0009       0.0276       0.0348       0.0009 22.8768
  139       0.0008       0.0277       0.0346       0.0009 22.5230
  140       0.0010       0.0271       0.0345       0.0009 22.2575
  141       0.0010       0.0270       0.0344       0.0009 22.9479
  142       0.0010       0.0269       0.0343       0.0009 21.9460
  143       0.0010       0.0278       0.0342       0.0010 21.9651
  144       0.0007       0.0277       0.0340       0.0009 21.6488
  145       0.0007       0.0274       0.0338       0.0009 21.4245
  146       0.0008       0.0268       0.0337       0.0009 20.4127
  147       0.0008       0.0265       0.0335       0.0009 20.3775
  148       0.0006       0.0267       0.0334       0.0009 21.4116
  149       0.0006       0.0268       0.0333       0.0009 21.2153
  150       0.0009       0.0274       0.0332       0.0009 20.8648
  151       0.0008       0.0277       0.0331       0.0009 20.8547
  152       0.0007       0.0275       0.0329       0.0009 21.3376
  153       0.0006       0.0270       0.0327       0.0009 20.4067
  154       0.0007       0.0276       0.0326       0.0009 20.2239
  155       0.0005       0.0274       0.0325       0.0009 20.3523
  156       0.0006       0.0271       0.0324       0.0009 20.4849
  157       0.0005       0.0275       0.0322       0.0009 19.3424
  158       0.0005       0.0275       0.0321       0.0009 19.1410
  159       0.0005       0.0277       0.0321       0.0009 18.8585
  160       0.0006       0.0271       0.0320       0.0009 18.6513
  161       0.0008       0.0268       0.0318       0.0009 18.5650
  162       0.0007       0.0267       0.0317       0.0009 19.4056
  163       0.0007       0.0270       0.0316       0.0009 18.9381
  164       0.0006       0.0266       0.0315       0.0009 18.9267
  165       0.0005       0.0261       0.0314       0.0008 18.7887
  166       0.0005       0.0255       0.0314       0.0008 19.0598
  167       0.0006       0.0254       0.0313       0.0008 19.5861
  168       0.0006       0.0256       0.0311       0.0008 19.2048
  169       0.0008       0.0264       0.0310       0.0009 18.5689
  170       0.0007       0.0272       0.0309       0.0009 18.6811
  171       0.0007       0.0267       0.0308       0.0009 18.6739
  172       0.0009       0.0258       0.0307       0.0008 19.1334
  173       0.0008       0.0252       0.0306       0.0008 19.2299
  174       0.0008       0.0252       0.0305       0.0008 19.1417
  175       0.0010       0.0258       0.0304       0.0008 19.1670
  176       0.0009       0.0256       0.0302       0.0008 18.3941
  177       0.0009       0.0255       0.0301       0.0008 19.1677
  178       0.0010       0.0254       0.0301       0.0008 19.3940
  179       0.0010       0.0259       0.0301       0.0008 19.0824
  180       0.0010       0.0252       0.0299       0.0008 19.1189
  181       0.0010       0.0248       0.0299       0.0008 20.0029
  182       0.0009       0.0243       0.0298       0.0007 19.8117
  183       0.0010       0.0248       0.0298       0.0008 19.8079
  184       0.0009       0.0245       0.0297       0.0007 19.6539
  185       0.0008       0.0242       0.0297       0.0007 19.6601
  186       0.0008       0.0243       0.0296       0.0007 19.5989
  187       0.0008       0.0246       0.0295       0.0007 20.5177
  188       0.0008       0.0243       0.0294       0.0007 20.4652
  189       0.0009       0.0240       0.0294       0.0007 19.7292
  190       0.0008       0.0239       0.0293       0.0007 19.7583
  191       0.0008       0.0237       0.0293       0.0007 20.2197
  192       0.0010       0.0242       0.0292       0.0007 19.6854
  193       0.0010       0.0238       0.0291       0.0007 19.8058
  194       0.0010       0.0237       0.0290       0.0007 19.7530
  195       0.0009       0.0229       0.0290       0.0007 20.7165
  196       0.0008       0.0231       0.0289       0.0007 20.0195
  197       0.0008       0.0229       0.0288       0.0007 20.7780
  198       0.0009       0.0228       0.0287       0.0006 20.1073
  199       0.0008       0.0228       0.0287       0.0006 20.7379
  200       0.0007       0.0229       0.0286       0.0006 20.0374
...Training Complete!

