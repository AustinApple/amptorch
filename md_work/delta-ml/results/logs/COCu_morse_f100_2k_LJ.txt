Thu Mar 12 15:38:21 2020
--------------------------------------------------
LJ-Parameter Optimization
inital LJ parameter guess [sig, eps]: {'C': [0.972, 6.379, 0.477], 'O': [1.09, 8.575, 0.603], 'Cu': [2.168, 3.8386, 1.696]}
Optimizer results: 
 fun: 0.05807756800558462 
 message: Max. number of function evaluations reached 
 nfev: 100 
 nit: 18 
 success: False
Fitted LJ parameters: {'C': array([1.        , 0.00867952, 1.21709183]), 'O': array([2.67198256, 6.84513676, 1.        ]), 'Cu': array([1.47657493, 0.05150728, 1.        ])} 

Optimization time: 410.78100180625916 

Filename: COCu_morse_f100_2k_LJ
Dataset size: 100
Target scaling: [8.841315589518457, -3.1748822875579803]
Symmetry function parameters:
     G2_etas: [0.05       0.23207944 1.07721735 5.        ]
     G2_rs_s: [0, 0, 0, 0]
     G4_etas: [0.005, 0.01]
     G4_zetas: [1.0, 4.0]
     G4_gammas: [1.0, -1]
     cutoff: 5.876798323827276
Device: cpu
Model: FullNN(
  (elementwise_models): ModuleDict(
    (Cu): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=60, out_features=20, bias=True)
        (1): Tanh()
        (2): Linear(in_features=20, out_features=20, bias=True)
        (3): Tanh()
        (4): Linear(in_features=20, out_features=1, bias=True)
      )
    )
    (O): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=60, out_features=20, bias=True)
        (1): Tanh()
        (2): Linear(in_features=20, out_features=20, bias=True)
        (3): Tanh()
        (4): Linear(in_features=20, out_features=1, bias=True)
      )
    )
    (C): MLP(
      (model_net): Sequential(
        (0): Linear(in_features=60, out_features=20, bias=True)
        (1): Tanh()
        (2): Linear(in_features=20, out_features=20, bias=True)
        (3): Tanh()
        (4): Linear(in_features=20, out_features=1, bias=True)
      )
    )
  )
)
Architecture:
   Input Layer - 60
   # of Hidden Layers - 2
   Nodes/Layer - 20
Loss Function: <class 'amptorch.model.CustomLoss'>
Force coefficient: 0.04
Optimizer: <class 'torch.optim.lbfgs.LBFGS'>
Learning Rate: 0.1
Batch Size: 100
Epochs: 200
Shuffle: False
Train Split (k-fold if int, fraction if float): 5

Training initiated...
Epoch   EnergyRMSE    ForceRMSE    TrainLoss    ValidLoss     Dur
===== ============ ============ ============ ============ =======
    1       0.0062       0.1438       0.9963       0.0087  7.0273
    2       0.0031       0.0866       0.0529       0.0031  6.6392
    3       0.0036       0.0821       0.0326       0.0028  6.4293
    4       0.0021       0.0988       0.0287       0.0039  6.4499
    5       0.0009       0.0617       0.0183       0.0015  7.0934
    6       0.0019       0.0546       0.0107       0.0012  7.2337
    7       0.0007       0.0429       0.0072       0.0007  5.8133
    8       0.0009       0.0371       0.0054       0.0006  5.6428
    9       0.0007       0.0437       0.0043       0.0008  6.3231
   10       0.0007       0.0395       0.0041       0.0006  5.6309
   11       0.0006       0.0445       0.0038       0.0008  6.0637
   12       0.0006       0.0404       0.0036       0.0007  6.9058
   13       0.0004       0.0389       0.0034       0.0006  6.4939
   14       0.0008       0.0386       0.0033       0.0006  6.0208
   15       0.0006       0.0386       0.0032       0.0006  5.1839
   16       0.0007       0.0380       0.0031       0.0006  5.7828
   17       0.0009       0.0400       0.0031       0.0006  5.3349
   18       0.0005       0.0353       0.0030       0.0005  5.5026
   19       0.0009       0.0352       0.0029       0.0005  7.1958
   20       0.0005       0.0313       0.0029       0.0004  7.2652
   21       0.0005       0.0314       0.0028       0.0004  6.3162
   22       0.0003       0.0315       0.0027       0.0004  7.1368
   23       0.0004       0.0322       0.0027       0.0004  6.6857
   24       0.0002       0.0324       0.0026       0.0004  7.1719
   25       0.0002       0.0296       0.0026       0.0004  7.0246
   26       0.0004       0.0282       0.0025       0.0003 28.2626
   27       0.0003       0.0281       0.0025       0.0003 29.9409
   28       0.0003       0.0290       0.0024       0.0003  5.2153
   29       0.0002       0.0288       0.0024       0.0003  5.8605
   30       0.0004       0.0262       0.0023       0.0003  7.1326
   31       0.0003       0.0257       0.0023       0.0003  7.6177
   32       0.0003       0.0249       0.0023       0.0002  6.3920
   33       0.0004       0.0258       0.0023       0.0003  5.7989
   34       0.0003       0.0261       0.0022       0.0003  5.6316
   35       0.0005       0.0277       0.0022       0.0003  5.0681
   36       0.0005       0.0301       0.0022       0.0004  6.2552
   37       0.0005       0.0341       0.0021       0.0005  6.4503
   38       0.0006       0.0395       0.0020       0.0006  6.5470
   39       0.0005       0.0429       0.0020       0.0007  7.2330
   40       0.0006       0.0474       0.0020       0.0009  6.7679
   41       0.0005       0.0393       0.0019       0.0006  7.0622
   42       0.0005       0.0372       0.0019       0.0006  7.0967
   43       0.0004       0.0361       0.0019       0.0005  7.4772
   44       0.0004       0.0330       0.0019       0.0004  6.7102
   45       0.0004       0.0370       0.0018       0.0006  6.5637
   46       0.0003       0.0324       0.0018       0.0004  6.7795
   47       0.0004       0.0323       0.0018       0.0004  7.9013
   48       0.0003       0.0365       0.0018       0.0005  8.1684
   49       0.0003       0.0348       0.0017       0.0005  7.7436
   50       0.0002       0.0296       0.0017       0.0004  8.0519
   51       0.0003       0.0254       0.0017       0.0003  6.4358
   52       0.0001       0.0226       0.0017       0.0002  7.6494
   53       0.0002       0.0231       0.0016       0.0002  5.8116
   54       0.0002       0.0210       0.0016       0.0002  5.8403
   55       0.0002       0.0208       0.0016       0.0002  6.0647
   56       0.0001       0.0204       0.0016       0.0002  7.7372
   57       0.0001       0.0210       0.0016       0.0002  6.7259
   58       0.0002       0.0210       0.0015       0.0002  6.4893
   59       0.0001       0.0209       0.0015       0.0002  7.1974
   60       0.0001       0.0203       0.0015       0.0002  5.9920
   61       0.0001       0.0204       0.0015       0.0002  5.5310
   62       0.0000       0.0196       0.0015       0.0002  5.5735
   63       0.0001       0.0203       0.0014       0.0002  5.6863
   64       0.0001       0.0206       0.0014       0.0002  5.3472
   65       0.0002       0.0214       0.0014       0.0002  5.4845
   66       0.0001       0.0196       0.0014       0.0002  5.3688
   67       0.0002       0.0201       0.0014       0.0002  5.0927
   68       0.0001       0.0187       0.0014       0.0001  5.1927
   69       0.0001       0.0195       0.0014       0.0002  4.9805
   70       0.0001       0.0188       0.0013       0.0001  5.3350
   71       0.0001       0.0180       0.0013       0.0001  5.7718
   72       0.0001       0.0182       0.0013       0.0001  5.3814
   73       0.0001       0.0200       0.0013       0.0002  5.7263
   74       0.0000       0.0204       0.0013       0.0002  5.5207
   75       0.0000       0.0197       0.0013       0.0002  5.8092
   76       0.0001       0.0197       0.0013       0.0002  5.4200
   77       0.0000       0.0185       0.0013       0.0001  5.9542
   78       0.0000       0.0179       0.0012       0.0001  4.8016
   79       0.0000       0.0178       0.0012       0.0001 159.5734
   80       0.0000       0.0172       0.0012       0.0001  4.9778
   81       0.0001       0.0166       0.0012       0.0001  5.1974
   82       0.0000       0.0163       0.0012       0.0001  4.7210
   83       0.0000       0.0164       0.0012       0.0001  4.8243
   84       0.0000       0.0156       0.0012       0.0001  4.8995
   85       0.0001       0.0154       0.0012       0.0001  4.9435
   86       0.0001       0.0157       0.0011       0.0001  4.9015
   87       0.0002       0.0152       0.0011       0.0001  4.9459
   88       0.0002       0.0149       0.0011       0.0001  5.0035
   89       0.0002       0.0145       0.0011       0.0001  4.0039
   90       0.0002       0.0150       0.0011       0.0001  4.8981
   91       0.0002       0.0149       0.0011       0.0001  4.8570
   92       0.0001       0.0156       0.0011       0.0001  4.8525
   93       0.0002       0.0163       0.0011       0.0001  4.8122
   94       0.0001       0.0171       0.0010       0.0001  5.0984
   95       0.0001       0.0175       0.0010       0.0001  4.8710
   96       0.0001       0.0174       0.0010       0.0001  4.8851
   97       0.0001       0.0182       0.0010       0.0001  4.7086
   98       0.0001       0.0172       0.0010       0.0001  4.6962
   99       0.0001       0.0174       0.0010       0.0001  4.9222
  100       0.0001       0.0177       0.0010       0.0001  4.9413
  101       0.0001       0.0168       0.0010       0.0001  4.6925
  102       0.0001       0.0170       0.0010       0.0001  4.8880
  103       0.0002       0.0171       0.0010       0.0001  4.8625
  104       0.0001       0.0165       0.0010       0.0001  4.7353
  105       0.0001       0.0168       0.0010       0.0001  5.1984
  106       0.0001       0.0165       0.0010       0.0001  4.9553
  107       0.0001       0.0166       0.0010       0.0001  5.2346
  108       0.0001       0.0166       0.0010       0.0001  4.7323
  109       0.0001       0.0176       0.0009       0.0001  4.7417
  110       0.0001       0.0181       0.0009       0.0001  4.7207
  111       0.0001       0.0187       0.0009       0.0001  4.8839
  112       0.0001       0.0191       0.0009       0.0001  4.7238
  113       0.0001       0.0187       0.0009       0.0001  4.9377
  114       0.0001       0.0175       0.0009       0.0001  4.6983
  115       0.0001       0.0181       0.0009       0.0001  4.6795
  116       0.0001       0.0179       0.0009       0.0001  4.6971
  117       0.0001       0.0180       0.0009       0.0001  4.6946
  118       0.0001       0.0184       0.0009       0.0001  4.6907
  119       0.0001       0.0169       0.0009       0.0001  4.7651
  120       0.0001       0.0175       0.0009       0.0001  4.0208
  121       0.0001       0.0168       0.0009       0.0001  4.7101
  122       0.0001       0.0175       0.0008       0.0001  4.7078
  123       0.0001       0.0171       0.0008       0.0001  4.8656
  124       0.0001       0.0164       0.0008       0.0001  4.6998
  125       0.0001       0.0170       0.0008       0.0001  4.9534
  126       0.0001       0.0170       0.0008       0.0001  4.6768
  127       0.0001       0.0189       0.0008       0.0001  4.6717
  128       0.0001       0.0192       0.0008       0.0001  4.7013
  129       0.0001       0.0193       0.0008       0.0001  4.8674
  130       0.0001       0.0192       0.0008       0.0001  4.7000
  131       0.0001       0.0174       0.0008       0.0001  4.6878
  132       0.0001       0.0167       0.0008       0.0001  4.9236
  133       0.0001       0.0154       0.0008       0.0001  4.7220
  134       0.0001       0.0156       0.0007       0.0001  4.8699
  135       0.0001       0.0151       0.0007       0.0001  4.6834
  136       0.0001       0.0142       0.0007       0.0001  4.6794
  137       0.0001       0.0144       0.0007       0.0001  4.7688
  138       0.0001       0.0143       0.0007       0.0001  4.8815
  139       0.0000       0.0136       0.0007       0.0001  4.8730
  140       0.0000       0.0132       0.0007       0.0001  4.8656
  141       0.0000       0.0138       0.0007       0.0001  4.8617
  142       0.0000       0.0133       0.0007       0.0001  4.8687
  143       0.0000       0.0131       0.0007       0.0001  4.6960
  144       0.0000       0.0139       0.0007       0.0001  4.9111
  145       0.0000       0.0141       0.0007       0.0001  4.6478
  146       0.0001       0.0135       0.0007       0.0001  4.8142
  147       0.0001       0.0138       0.0006       0.0001  4.6725
  148       0.0001       0.0138       0.0006       0.0001  4.6657
  149       0.0001       0.0128       0.0006       0.0001  4.8355
  150       0.0001       0.0130       0.0006       0.0001  4.8885
  151       0.0000       0.0124       0.0006       0.0001  4.6587
  152       0.0001       0.0127       0.0006       0.0001  4.6603
  153       0.0001       0.0129       0.0006       0.0001  4.8461
  154       0.0001       0.0130       0.0006       0.0001  4.8214
  155       0.0001       0.0138       0.0006       0.0001  4.7068
  156       0.0001       0.0150       0.0006       0.0001  4.6744
  157       0.0001       0.0151       0.0006       0.0001  4.8531
  158       0.0001       0.0160       0.0006       0.0001  4.6650
  159       0.0001       0.0161       0.0006       0.0001  4.6720
  160       0.0002       0.0152       0.0006       0.0001  4.6735
  161       0.0002       0.0169       0.0006       0.0001  4.7080
  162       0.0002       0.0167       0.0006       0.0001  4.6740
  163       0.0001       0.0167       0.0006       0.0001  4.8552
  164       0.0001       0.0165       0.0006       0.0001  4.7220
  165       0.0001       0.0156       0.0006       0.0001  4.6812
  166       0.0001       0.0153       0.0006       0.0001  4.8787
  167       0.0002       0.0159       0.0006       0.0001  4.7125
  168       0.0001       0.0164       0.0006       0.0001  4.8816
  169       0.0001       0.0165       0.0006       0.0001  4.7360
  170       0.0001       0.0171       0.0006       0.0001  4.8398
  171       0.0001       0.0175       0.0005       0.0001  4.6730
  172       0.0002       0.0191       0.0005       0.0001  4.6736
  173       0.0002       0.0204       0.0005       0.0002  4.8694
  174       0.0002       0.0216       0.0005       0.0002  4.6750
  175       0.0002       0.0215       0.0005       0.0002  4.8540
  176       0.0002       0.0214       0.0005       0.0002  4.6969
  177       0.0002       0.0221       0.0005       0.0002  4.7772
  178       0.0002       0.0229       0.0005       0.0002  4.6629
  179       0.0003       0.0246       0.0005       0.0002  4.7185
  180       0.0003       0.0255       0.0005       0.0003  4.6997
  181       0.0003       0.0255       0.0005       0.0003  4.6996
  182       0.0003       0.0267       0.0005       0.0003  4.6842
  183       0.0003       0.0265       0.0005       0.0003  4.7184
  184       0.0002       0.0255       0.0005       0.0003  4.6921
  185       0.0002       0.0261       0.0005       0.0003  4.8746
  186       0.0003       0.0264       0.0005       0.0003  4.7630
  187       0.0003       0.0263       0.0005       0.0003  4.8569
  188       0.0003       0.0260       0.0005       0.0003  4.8855
  189       0.0002       0.0252       0.0005       0.0003  4.6924
  190       0.0002       0.0247       0.0005       0.0002  4.8866
  191       0.0002       0.0248       0.0005       0.0002  4.7452
  192       0.0002       0.0248       0.0005       0.0002  4.7459
  193       0.0002       0.0250       0.0005       0.0003  4.7366
  194       0.0002       0.0245       0.0005       0.0002  4.9824
  195       0.0002       0.0239       0.0005       0.0002  4.9350
  196       0.0002       0.0240       0.0005       0.0002  4.8930
  197       0.0002       0.0251       0.0005       0.0003  4.8571
  198       0.0002       0.0246       0.0005       0.0002  4.7227
  199       0.0002       0.0256       0.0004       0.0003  4.6951
  200       0.0002       0.0260       0.0004       0.0003  4.7555
...Training Complete!

